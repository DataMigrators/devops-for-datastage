{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>The latest version can always be found here: https://pages.github.ibm.com/datamigrators/devops-for-datastage/</p> <p>Download the latest (PDF) Download the latest (DOCX)</p> <ul> <li> <p> Set up in 5 minutes</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p> </li> <li> <p> Open Source, MIT</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p> </li> </ul>"},{"location":"blog/","title":"Blog","text":""},{"location":"flow-analysis/flow-analysis/","title":"Introduction","text":"<p>The latest version can always be found here: https://pages.github.ibm.com/datamigrators/devops-for-datastage/</p> <p>Download the latest (PDF) Download the latest (DOCX)</p> <ul> <li> <p> Set up in 5 minutes</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p> </li> <li> <p> Open Source, MIT</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p> </li> </ul>"},{"location":"mettleci-cli/command-shell/","title":"MettleCI Command Shell","text":"<p>The MettleCI Command Line Interface is available from either your Windows command line or Unix shell.  It provides one way of accessing MettleCI's build and deployment functions, and supports two different modes of operation: console or command line.  MettleCI commands accept various parameters which can optionally be sourced from a command file.</p>","tags":["DATASTAGE","TESTING"]},{"location":"mettleci-cli/command-shell/#console-mode","title":"Console Mode","text":"<p>To enter console mode start the MettleCI Command Line Interface by entering <code>mettleci</code> (UNIX) or <code>mettleci.cmd</code> (Windows).</p> <pre><code>C:\\&gt; mettleci.cmd\nMettleCI Command Line\n(C)2019 Data Migrators Pty Ltd\nEnter [namespace] [command] {options}\nor 'help', 'exit', or 'quit'.\nmettleci&gt;\n</code></pre> <p>In console mode MettleCI prints a command prompt and waits for a command. Each command is processed without exiting MettleCI. You may need to provide authentication options for a commands which invoke functionality in third party systems.  You can enter help to get assistance, or exit the console mode by entering exit, or quit at the prompt.</p>","tags":["DATASTAGE","TESTING"]},{"location":"mettleci-cli/command-shell/#command-mode","title":"Command mode","text":"<p>In command mode you can enter commands one at a time at your operating system's command line. Start each command (omitting the quotes) with <code>mettleci</code> (unix) or <code>mettleci.cmd</code> (Windows) followed by a namespace and command, then the parameters.</p> <p>Open image2019-10-25_22-51-19.png</p> <p>Some of the available commands (listed below) use IBM DataStage client components, and so are platform specific.  For example, job compilation requires access to Windows-only components, and so will not be supported on Unix environments.  The MettleCI command is followed by a namespace, which groups a collection of build and deployment operations.  Each of these commands accepts a number of mandatory and/or optional parameters. </p> <pre><code>mettleci [namespace] [command] {commandoptions}\n</code></pre> <p>Here's an example of the MettleCI Command Line being used to compile an entire DataStage project (using the 'compile' command provided by the 'datastage' namespace) :</p> <pre><code># Note that the example below uses the line continuation charactere ('\\' on Unix or '^' on Windows)\n# to aid readability, but your mettleci command line can all be on a single line if you prefer \n$&gt; mettleci datastage compile \\\n   -domain test1-svcs.datamigrators.io:59445 \\\n   -server test1-engn.datamigrators.io -project dstage1 \\\n   -username isadmin -password isadminpwd\nAnalyzing assets to compile\nCompilation folder location = C:\\Apps\\command-shell\\log\\compiliation\nAttempting to compile with 4 working threads.\nCompiling DataStage jobs...\n * Compile 'test2-engn.datamigrators.io/dstage1/Jobs/Load/EX_Account.pjb' - COMPLETED\n [SNIP]\n * Compile 'test2-engn.datamigrators.io/dstage1/Jobs/Load/TX_StockHolding.pjb' - COMPLETED\nCompilation complete\n$&gt; \n</code></pre> <p>Note that MettleCI Command Line namespaces, commands, and options are all case sensitive. </p>","tags":["DATASTAGE","TESTING"]},{"location":"mettleci-cli/command-shell/#use-a-password-containing-special-characters","title":"Use a password containing special characters","text":"<p>If the password contains special characters, you will need to wrap it with single or double quote or by using escape characters.</p> Password contains Windows-based Unix-based ! (exclamation) Use password without modification. For example: MyPassword! Wrap password with single quote.  For example: 'MyPassword!' \u201c (double quote) Use escape character . For example: My\u201dPassword Wrap password with single quote.  For example: 'My\"Password' ' (single quote) Wrap password with double quote.  For example: \u201cMy'Password\u201d Wrap password with single quote and use escape character .  For example: 'My'''Password' * (asterisk) Use password without modification. For example: My*Password Wrap password with single quote.  For example: 'My*Password' Wrap password with double quote.  For example: \u201cMy Password\u201d Wrap password with single quote.  For example: 'My Password'","tags":["DATASTAGE","TESTING"]},{"location":"mettleci-cli/command-shell/#using-external-command-files-with-the-mettleci-cli","title":"Using external command files with the MettleCI CLI","text":"<p>MettleCI allows you to define a MettleCI command in a text-based \u2018command file\u2019 and pass the file as parameter to the MettleCI command.  This is accomplished using the '@' command syntax: </p> <pre><code># Here's a typical command file\n$&gt; cat file mycommand.txt\ndatastage\ncompile\n-domain\ntest1-svcs.datamigrators.io:59445\n-username\nisadmin\n-password\nisadminpwd\n-server\ntest1-engn.datamigrators.io\n-project\ndstage1\n# ... and here's how to invoke it\n$&gt; mettleci @mycommand.txt\n</code></pre> Note <ul> <li>Each element of a command file needs to be on an individual line (i.e. separated by your operating system\u2019s newline ASCII character combination)</li> <li>A command file can only contain the definition of a single MettleCI command</li> <li>You can run the MettleCI Command Line with multiple commands by invoking it with individual command files from a shell script with one command per line. e.g.</li> </ul> <pre><code>#!/usr/bin/env bash\nmettleci @mycommand1.txt\nmettleci @mycommand2.txt\nmettleci @mycommand3.txt\n# etc.\n</code></pre>","tags":["DATASTAGE","TESTING"]},{"location":"mettleci-cli/compliance-namespace/","title":"Compliance namespace","text":"","tags":["PIPELINE","CLI","COMPLIANCE","TAGS"]},{"location":"mettleci-cli/compliance-namespace/#compliance-list-tags","title":"Compliance List Tags","text":"<p>This command analyses a specified set of Compliance Rules or Asset Queries and reports the tags defined for each.  Output is available in an easy-to-read tabulated for, or as a CSV for downstream processing. When no format optin</p>","tags":["PIPELINE","CLI","COMPLIANCE","TAGS"]},{"location":"mettleci-cli/compliance-namespace/#example","title":"Example","text":"<p>This example shows how to list the tags of a directory of Compliance Rules in both tabulated and CSV formats:</p> <pre><code># ####################################\n# list-tags output in tabulated format\n# ####################################\n$&gt; mettleci compliance list-tags \\\n   -rules ~/Projects/bitbucket.org/compliance-rules \\\n   -format table\nMettleCI Command Line (build 174)\n(C) 2018-2022 Data Migrators Pty Ltd\ncompliance list-tags (v2.2.x)\nrules configuration discovered\nincluded rule - 'Adjacent Transformers' (PARALLEL_JOB)\nincluded rule - 'Adjacent Transformers' (SERVER_JOB)\n... &lt;SNIP&gt; ...\nincluded rule - 'Transformer With Unreferenced Stage Variable' (SERVER_JOB)\nincluded rule - 'Unique Sort' (PARALLEL_JOB)\n                                       Rule Name  Asset Type                 example  fail-ci  fail-upgrade  functionality  governance  maintainability  performance  portability  security  testability\n================================================  =========================  =======  =======  ============  =============  ==========  ===============  ===========  ===========  ========  ===========\n                           Adjacent Transformers  PARALLEL_JOB               -------  -------  ------------  -------------  ----------  maintainability  -----------  -----------  --------  -----------\n                           Adjacent Transformers  SERVER_JOB                 -------  -------  ------------  -------------  ----------  maintainability  -----------  -----------  --------  -----------\n                                Audit Annotation  PARALLEL_JOB               example  -------  ------------  -------------  ----------  maintainability  -----------  -----------  security  -----------\n                                Audit Annotation  SEQUENCE_JOB               example  -------  ------------  -------------  ----------  maintainability  -----------  -----------  security  -----------\n                                Audit Annotation  SERVER_JOB                 example  -------  ------------  -------------  ----------  maintainability  -----------  -----------  security  -----------\n                                          &lt;SNIP&gt;  &lt;SNIP&gt;                     ...      ...      ...           ...            ...         ...              ...          ...          ...       ...\n               Transformer Uses Abort After Rows  PARALLEL_JOB               -------  -------  ------------  functionality  ----------  ---------------  -----------  -----------  --------  -----------\n               Transformer Uses Abort After Rows  PARALLEL_SHARED_CONTAINER  -------  -------  ------------  functionality  ----------  ---------------  -----------  -----------  --------  -----------\n    Transformer With Unreferenced Stage Variable  PARALLEL_JOB               -------  -------  ------------  functionality  ----------  maintainability  -----------  -----------  --------  -----------\n    Transformer With Unreferenced Stage Variable  SERVER_JOB                 -------  -------  ------------  functionality  ----------  maintainability  -----------  -----------  --------  -----------\n                                     Unique Sort  PARALLEL_JOB               -------  -------  ------------  -------------  ----------  maintainability  -----------  -----------  --------  -----------\n# ##############################\n# list-tags output in CSV format\n# ##############################\n$&gt; mettleci compliance list-tags \\\n   -rules ~/Projects/bitbucket.org/compliance-rules \\\n   -format csv\nMettleCI Command Line (build 174)\n(C) 2018-2022 Data Migrators Pty Ltd\ncompliance list-tags (v2.2-SNAPSHOT)\nrules configuration discovered\n... &lt;SNIP&gt; ...\nRule Name,Asset Type,example,fail-ci,fail-upgrade,functionality,governance,maintainability,performance,portability,security,testability\nAdjacent Transformers,PARALLEL_JOB,,,,,,maintainability,,,,\nAdjacent Transformers,SERVER_JOB,,,,,,maintainability,,,,\nAudit Annotation,PARALLEL_JOB,example,,,,,maintainability,,,security,\nAudit Annotation,SEQUENCE_JOB,example,,,,,maintainability,,,security,\nAudit Annotation,SERVER_JOB,example,,,,,maintainability,,,security,\n... &lt;SNIP&gt; ...\nTransformer With Unreferenced Stage Variable,PARALLEL_JOB,,,,functionality,,maintainability,,,,\nTransformer With Unreferenced Stage Variable,SERVER_JOB,,,,functionality,,maintainability,,,,\nUnique Sort,PARALLEL_JOB,,,,,,maintainability,,,,\n$&gt;\n</code></pre>","tags":["PIPELINE","CLI","COMPLIANCE","TAGS"]},{"location":"mettleci-cli/compliance-namespace/#compliance-query-command","title":"Compliance Query Command","text":"This command is for running MettleCI Asset Queries <p>If you're looking for the Compliance Rules returned by DataStage flow analysis then see the Compliance Test Command.</p> <p></p> <p>The command line implementation of the Compliance Query functionality exposes the low-level mechanism to produce a report listing the results of the specified Asset Queries.</p>","tags":["PIPELINE","CLI","COMPLIANCE","TAGS"]},{"location":"mettleci-cli/compliance-namespace/#example_1","title":"Example","text":"<p>This example demonstrates how to export  a set of ISX files and run Asset Queries against them. Note that asset paths specification in the export command uses the same wildcard rules as the istool command.</p> <pre><code># ============================== \n# Export the required ISX assets\n# ============================== \nC:\\&gt; mettleci isx export ^\n     -domain myteam-svcs.corp.com:59445 ^\n     -username myuser -password mypassword ^\n     -server myteam-engn.corp.com ^\n     -project myproject ^\n     -jobname .*LD_S.*\nExporting [.*LD_S.*] from repository...\nExporting DataStage assets...\n * Export 'test2-engn.datamigrators.io/myproject/Jobs/Load/LD_SUPPLIER.pjb' - COMPLETED\n * Export 'test2-engn.datamigrators.io/myproject/Jobs/Load/LD_STOCK_HOLDING.pjb' - COMPLETED\n * Export 'test2-engn.datamigrators.io/myproject/Jobs/Load/LD_STOCKITEM.pjb' - COMPLETED\n * Export 'test2-engn.datamigrators.io/myproject/Jobs/Load/LD_SALE.pjb' - COMPLETED\nExport complete\n# ================================================================\n# Run the specified asset queries against the exported ISX assets\n# ================================================================\nC:\\&gt; mettleci compliance query \\\n     -assets ./Jobs \\\n     -queries ./Queries \\\n     -report compliance.csv \\\nMettleCI Command Line (build 122)\n(C) 2018-2020 Data Migrators Pty Ltd\n &lt;SNIP&gt;\n# Done!\nC:\\&gt;\n</code></pre>","tags":["PIPELINE","CLI","COMPLIANCE","TAGS"]},{"location":"mettleci-cli/compliance-namespace/#compliance-test-command","title":"Compliance Test Command","text":"This command is for running MettleCI Compliance Rules <p>If you're looking for the Asset Queries typically used in a MettleCI Report Card then please see the Compliance Query Command.</p> <p></p> <p>The command line implementation of the Compliance Test functionality enables the production of a Compliance Results report of the specified assets against the specified set of MettleCI Compliance Rules.</p> <p>For more information on using the <code>-project-cache</code> parameter see our detailed explanation.</p>","tags":["PIPELINE","CLI","COMPLIANCE","TAGS"]},{"location":"mettleci-cli/compliance-namespace/#example_2","title":"Example","text":"<p>This example demonstrates how to export  a set of ISX files and run Compliance against them. Note that asset paths specification in the export command uses the same wildcard rules as the istool command.</p> <pre><code># ============================== \n# Export the required ISX assets\n# ============================== \nC:\\MettleCI\\cli\\&gt; mettleci isx export ^\n     -domain myteam-svcs.corp.com:59445 ^\n     -username myuser -password mypassword  ^\n     -server myteam-engn.corp.com  ^\n     -project myproject  ^\n     -location C:\\shared\\myproject\\export  ^\n     -include-binaries  ^\n     -project-cache C:\\shared\\myproject\\cache\nAnalyzing test2-engn.datamigrators.io/myproject\nAttempting to identify changes with 4 working threads.\nInspecting DataStage assets for changes...\n&lt;SNIP&gt;\nChange identification complete\nInspecting ParameterSet definition changes...\nParameterSet definition change identification complete\nDeleting assets...\n&lt;SNIP&gt;\nDeletion complete\nExporting DataStage assets...\n&lt;SNIP&gt;\nExport complete\nAttempting to identify last change with 4 working threads.\nInspecting DataStage assets for last change...\n&lt;SNIP&gt;\nLast change identification complete\n# ==================================================================\n# Run the specified compliance rules against the exported ISX assets\n# ==================================================================\n$&gt; mettleci compliance test\n  -rules compliance_rules\n  -assets datastage\n  -report compliance_report_warn.xml\n  -junit\n  -project-cache ./project-cache\n  -test-suite warnings\n  -ignore-test-failures\n  -include-job-in-test-name\nMettleCI Command Line (build 122)\n(C) 2018-2020 Data Migrators Pty Ltd\nrules configuration discovered\nnew rule discovered - 'Adjacent Transformers' (PARALLEL_JOB)\nnew rule discovered - 'CCMigrateTool Stages' (PARALLEL_JOB)\nnew rule discovered - 'CCMigrateTool Stages' (SERVER_JOB)\nnew rule discovered - 'Database Row Limit' (PARALLEL_JOB)\nnew rule discovered - 'Database Row Limit' (SERVER_JOB)\nnew rule discovered - 'Debug Row Limit' (PARALLEL_JOB)\n&lt;SNIP&gt;\nnew rule discovered - 'One Dataflow' (SERVER_JOB)\nnew rule discovered - 'Range Lookup' (PARALLEL_JOB)\nnew rule discovered - 'Too Many Stages' (PARALLEL_JOB)\nnew rule discovered - 'Too Many Stages' (SERVER_JOB)\nnew rule discovered - 'Unique Sort' (PARALLEL_JOB)\n[1/3] TestJob_0921 (PARALLEL_JOB)\n[2/3] TestJob_0930 (PARALLEL_JOB)\n[3/3] TestJob (PARALLEL_JOB)\n# Done!\n$&gt;\n</code></pre>","tags":["PIPELINE","CLI","COMPLIANCE","TAGS"]},{"location":"mettleci-cli/compliance-namespace/#references","title":"References","text":"<p>For a discussion on the use of the <code>include-tags</code> and <code>exclude-tags</code> options see Compliance Rule Tags.</p>","tags":["PIPELINE","CLI","COMPLIANCE","TAGS"]},{"location":"mettleci-cli/project-cache-directory/","title":"The CLI 'project-cache' directory","text":"","tags":["CLI"]},{"location":"mettleci-cli/project-cache-directory/#project-cache-directory","title":"Project Cache directory","text":"<p>The <code>-project-cache</code> parameter, which refers to a filesystem directory, is used with some MettleCI CLI commands to enable incremental operations. The directory supplied to the <code>-project-cache</code> option is the location where the CLI will read/write state information (sometimes referred to as asset fingerprints) used for performing incremental operations.  This directory should exist wherever the MettleCI CLI executes a command which relies on incremental behaviour, which normally occurs on the MettleCI Agent host under the instruction of your build agent.</p> <p>In the sample pipelines shipped with MettleCI the incremental MettleCI CLI commands, assume the use of a locally-stored project cache and refer to the following project cache location:</p> <pre><code>%AGENTMETTLEHOME%\\cache\\%IISENGINENAME%\\%DATASTAGE_PROJECT%\n</code></pre> <p>\u2026 which will normally translate to something similar to \u2026</p> <pre><code>C:\\MettleCI\\CLI\\cache\\MY.ENGINE.HOSTNAME\\MyDataStageProject\\\n</code></pre> Note <p>The project cache will always be a Windows-style filesystem reference (using backslashes), as many of the MettleCI CLI commands required in a CI/CD pipeline for pre-NextGen DataStage rely on Windows-only DataStage Client utilities.</p> <p>There are a few things which need to be considered when deciding the location of project cache directories:</p> <ul> <li> <p>The directory must be unique to a DataStage project</p> </li> <li> <p>It must be directly accessible from the CLI (i.e.. You can't specify an engine path if the CLI is running on a Client)</p> </li> <li> <p>ADVANCED: If multiple instances of the CLI are to be used for incremental operations (and hence multiple independent CLI instances need to share a common view of the incremental environment\u2019s status) then the -project-cache needs to be available and synchronised across all of those CLI instances.  This is normally achieved using shared storage.</p> </li> </ul>","tags":["CLI"]},{"location":"mettleci-cli/project-cache-directory/#using-multiple-cli-environments","title":"Using multiple CLI environments","text":"<p>The last point becomes important if you are running a \u2018pool\u2019 of agents on the CI/CD pipeline.  If they were to all maintain their own independent copies of the -project-cache files then incremental fingerprints will differ between CLI instances, resulting in a significant drop in the performance benefits delivered by the incremental approach.</p> <p>As an example of what could happen if a mettleci datastage deploy  command deploys to the same DataStage project with two different -project-cache directories:</p> <ol> <li>Initial Deployment using MyCache<ol> <li>Command mettleci datastage deploy \u2026 -project-cache MyCache is invoked.</li> <li>This imports and compiles all ISX files as MyCache does not currently contain any stage information.</li> <li>This initially expensive process will always be required to establish. the initial contents of the project cache.</li> </ol> </li> <li>First Deployed Change using OtherCache<ol> <li>Job MyFirstJob is checked in.</li> <li>Command mettleci datastage deploy \u2026 -project-cache OtherCache is invoked.</li> <li>This imports and compiles all ISX files as OtherCache does not currently contain any stage information.</li> </ol> </li> <li>Second Deployed Change using MyCache<ol> <li>Command mettleci datastage deploy \u2026 -project-cache MyCache is run.</li> <li>This compares the Git codebase to the target DataStage environment and sees that all fingerprints are misaligned.  The command consequently re-imports and re-compiles all ISX files as MyCache contains state information which is not aligned with the target.  This could have been avoided using the proper project cache.</li> </ol> </li> </ol> <p>Alternatively you can use you agent labelling strategy to ensure that only a single CLI instance is used by your pipeline which eliminates the need to coordinate the project-cache amongst multiple environments.  In these cases a locally-stored project cache can be used.  If you subsequently decide to horizontally scale your agent capability then you will need to\u2026</p> <ol> <li>move your project cache to shared storage, and </li> <li>Modify your build pipelines to refer to that new shared location.</li> </ol>","tags":["CLI"]},{"location":"overview/","title":"Overview","text":"<p>Start here.</p>"},{"location":"patterns/testing-datastage-containers/","title":"Testing local and shared containers","text":"This patterns is handled automatically for you by DataStage <p>For DataStage flows that use this pattern the DataStage test case creation process will generate an appropriately structured test case specification. This page acts as a reference to explain the structure of the generated JSON test specification.</p> <p>Let's take a simple example of a DataStage test case:</p> <p></p> <p>Containers (both local and shared) complicate this situation as stage names in DataStage are only unique within a given flow or container.  </p> <p>Consider writing a test specification for the following flow, <code>ProcessAccounts</code>, which includes a shared container stage <code>ContainerC1</code> which is itself a reference to the shared container <code>scWriteAccounts</code>:</p> <p>Flow <code>ProcessAccounts</code>: </p> <p>Container <code>scWriteAccounts</code>:  |</p> <p>You might be tempted to create a spec like this \u2026</p> <pre><code>{\n    \"given\": [\n        {\n            \"path\": \"given.csv\",\n            \"stage\": \"sfInput\",\n            \"link\": \"in\" \n        }\n    ],\n    \"when\": {},\n    \"then\": [\n        {\n            \"path\": \"expected.csv\",\n            \"stage\": \"sfOutput\",\n            \"link\": \"out\"\n        }\n    ]\n}\n</code></pre> <p>The resulting Unit Test Spec is ambiguous because the MettleCI Unit Test Harness will not be able to uniquely identify which Unit Test Data file is associated with each sqAccounts stage.  To avoid these sort of issues, the stage properties within Unit Test Specs expect fully qualified stage names.  A fully qualified stage name is prefixed with any relevant parent Container names using the format <code>&lt;container name&gt;.&lt;stage name&gt;</code>.</p> <p>Here\u2019s an example of a fully qualified stage name:</p> <pre><code>{\n    \"given\": [\n        {\n            \"path\": \"given.csv\",\n            \"stage\": \"sfInput\",\n            \"link\": \"in\" \n        }\n    ],\n    \"when\": {},\n    \"then\": [\n        {\n            \"path\": \"expected.csv\",\n            \"stage\": \"subflow_1.sfOutput\",\n            \"link\": \"out\"\n        }\n    ]\n}\n</code></pre>","tags":["DATASTAGE","TESTING"]},{"location":"patterns/testing-datastage-flow-rejects/","title":"Testing stage rejects","text":"<p>Most DataStage jobs can be tested via MettleCI\u2019s Unit Testing function simply by replacing input and output stages. However, some job designs - while commonplace - will necessitate a more advanced Unit Testing configuration.  The sections below outline MettleCI Unit Test Spec patterns that best match these job designs.</p> This patterns is handled automatically for you by DataStage <p>For DataStage flows that use this pattern the DataStage test case creation process will generate an appropriately structured test case specification. This page acts as a reference to explain the structure of the generated JSON test specification.</p>","tags":["DATASTAGE","TESTING"]},{"location":"patterns/testing-datastage-flow-rejects/#input-stage-with-rejects","title":"Input stage with rejects","text":"<p>The Input stage can be Unit Tested by including both read and reject links in the given clause of the Unit Test Spec.</p> <p>The CSV data specified for the rejects link should contain records that will actually test the flow of records through the reject path(s) of the job.</p>","tags":["DATASTAGE","TESTING"]},{"location":"patterns/testing-datastage-flow-rejects/#flow-design","title":"Flow design","text":"","tags":["DATASTAGE","TESTING"]},{"location":"patterns/testing-datastage-flow-rejects/#test-specification","title":"Test specification","text":"<pre><code>{\n   \"given\": [\n      {\n         \"stage\": \"Input\",\n         \"link\": \"Read\" \n         \"path\": \"Input-Read.csv\",\n      },\n      {\n         \"stage\": \"Input\",\n         \"link\": \"Rejects\" \n         \"path\": \"Input-Rejects.csv\",\n      }\n   ],\n   \"when\": {\n      \"parameters\": { }\n   },\n   \"then\": [\n   ]\n}\n</code></pre>","tags":["DATASTAGE","TESTING"]},{"location":"patterns/testing-datastage-flow-rejects/#result","title":"Result","text":"","tags":["DATASTAGE","TESTING"]},{"location":"patterns/testing-datastage-flow-rejects/#output-stage-with-rejects","title":"Output stage with rejects","text":"<p>The output stage can be Unit Tested by including:</p> <ul> <li>the write link in the then clause of the Unit Test Spec; and</li> <li>the reject in the given clause of the Unit Test Spec.</li> </ul> <p>The CSV data specified for the rejects link should contain records that will actually test the flow of records through the reject path(s) of the job.</p>","tags":["DATASTAGE","TESTING"]},{"location":"patterns/testing-datastage-flow-rejects/#flow-design_1","title":"Flow design","text":"","tags":["DATASTAGE","TESTING"]},{"location":"patterns/testing-datastage-flow-rejects/#test-specification_1","title":"Test specification","text":"<pre><code>{\n   \"given\": [\n      {\n         \"stage\": \"Output\",\n         \"link\": \"Rejects\",\n         \"path\": \"Output-Rejects.csv\"\n      }\n   ],\n   \"when\": {\n      \"parameters\": { }\n   },\n   \"then\": [\n      {\n         \"stage\": \"Output\",\n         \"link\": \"Write\",\n         \"path\": \"Output-Write.csv\"\n      }\n   ]\n}\n</code></pre>","tags":["DATASTAGE","TESTING"]},{"location":"patterns/testing-datastage-flow-rejects/#result_1","title":"Result","text":"","tags":["DATASTAGE","TESTING"]},{"location":"patterns/testing-datastage-stored-procedures/","title":"Testing stored procedure stages","text":"<p>A connector stage which supports stored procedures will not only connect to an external Database for processing but it will also produce output records which are not deterministic.  A DataStage test case specification needs to treat stored procedure-capable stages which will be stubbed during unit test execution.  This is done by adding the relevant stage's input link to the <code>then</code> clause of the test specification and the output link to the <code>given</code> clause.</p> <p>The CSV input specified by the given clause contains the data that will become the flow of records from the Stored Procedure stage. The data could simulate what would be produced by the real stored procedure if it had processed the Unit Test input records, however they don\u2019t have to.</p> <p>[!NOTE] This process is handled automatically by the DataStage test case creation process. This page acts as a reference to explain the structure of the JSON test specification generated for flows including following this pattern.</p>","tags":["DATASTAGE","TESTING"]},{"location":"patterns/testing-datastage-stored-procedures/#flow-design","title":"Flow design","text":"","tags":["DATASTAGE","TESTING"]},{"location":"patterns/testing-datastage-stored-procedures/#test-specification","title":"Test specification","text":"<pre><code>{\n    \"given\": [\n        {\n            \"path\": \"StoredProcedure-Output.csv\",\n            \"stage\": \"StoredProcedure\",\n            \"link\": \"Output\" \n        }\n    ],\n    \"then\": [\n        {\n            \"path\": \"StoredProcedure-Input.csv\",\n            \"stage\": \"StoredProcedure\",\n            \"link\": \"Input\"\n        }\n    ],\n    \"when\": {\n        \"parameters\": { }\n    }\n}\n</code></pre>","tags":["DATASTAGE","TESTING"]},{"location":"patterns/testing-datastage-stored-procedures/#result","title":"Result","text":"","tags":["DATASTAGE","TESTING"]},{"location":"patterns/testing-datastage-surrogate-key-generators/","title":"Testing surrogate key generator stages","text":"<p>Surrogate Key Generators are backed by a Database or a Flat File and will produce output records which are not deterministic.  The use of a Database-backed Surrogate Key Generator will also require a live connection to an external Database which is not ideal for unit testing.  To unit test flow designs containing this type of surrogate key generator, the surrogate key generator stage needs to be removed from the flow and replaced with test case data.  This is done by adding the input link in the <code>then</code> clause of the test specification and the output link in the <code>given</code> clause.</p> <p>The CSV input specified by the given clause contains the data that will become the flow of records from the surrogate key generator stage.  The data could simulate what would be produced by the real surrogate key generator if it had processed the test case input records, however it doesn\u2019t have to.  The easiest way to simulate the surrogate key generator output records would be to copy the CSV specified in the <code>then</code> clause and add a new column to represent the generated key and set appropriate key values.</p>","tags":["DATASTAGE","TESTING"]},{"location":"patterns/testing-datastage-surrogate-key-generators/#flow-design","title":"Flow design","text":"","tags":["DATASTAGE","TESTING"]},{"location":"patterns/testing-datastage-surrogate-key-generators/#test-specification","title":"Test specification","text":"<pre><code>{\n   \"given\": [\n      {\n         \"stage\": \"KeyGenerator\",\n         \"link\": \"Output\",\n         \"path\": \"KeyGenerator-Output.csv\"\n      }\n   ],\n   \"when\": {\n      \"parameters\": {\n         \"MyKeyStartValue\": 100\n      }\n   },\n   \"then\": [\n      {\n         \"stage\": \"KeyGenerator\",\n         \"link\": \"Input\",\n         \"path\": \"KeyGenerator-Input.csv\"\n      }\n   ]\n}\n</code></pre>","tags":["DATASTAGE","TESTING"]},{"location":"patterns/testing-datastage-surrogate-key-generators/#result","title":"Result","text":"","tags":["DATASTAGE","TESTING"]},{"location":"patterns/testing-flows-using-datetime-references/","title":"Testing date/time references","text":"<p>Repeatable DataStage tests require that the flow being tested produces deterministic data based on a set of predefined inputs and parameters.  Calculations based on the current date or time are common in DataStage flow designs but will cause the output produced by those flows to change depending on the date and time when its job is executed.  This page outlines practices aimed at ensuring jobs using current date calculations are able to be validly tested.</p>","tags":["DATASTAGE","TESTING"]},{"location":"patterns/testing-flows-using-datetime-references/#transformer-stages-using-system-time-and-date-functions","title":"Transformer Stages using system time and date functions","text":"<p>Transformer stages with derivations using the <code>CurrentDate()</code>, <code>CurrentTime()</code> or <code>CurrentTimestamp()</code> functions need to be considered carefully whn designing your tests. Unless your calculation requires a specific date and/or time then calls to the standard <code>CurrentDate()</code>, <code>CurrentTime()</code> and <code>CurrentTimestamp()</code> functions could potentially be substituted with calls to the <code>DSJobStartDate</code>, <code>DSJobStartTime</code> and <code>DSJobStartTimestamp</code> macros. This enables you to substitute them with a specific value during testing.  Add <code>DSJobStartDate</code>, <code>DSJobStartTime</code>, and <code>DSJobStartTimestamp</code> (as required) to the <code>parameters</code> clause of the test Specification's <code>when</code> node and set the appropriate date and time values used during Unit Testing.</p> <p>For example, imagine two Transformer stage variables using the following expressions:</p> <pre><code>BeforeToday =\nIf inPurchases.Purchase_Date &lt; DSJobStartDate Then \"Yes\" else \"No\"\n\nEarlierToday = \nIf inPurchases.Purchase_Date = DSJobStartDate and \n   inPurchases.Purchase_Time &lt; DSJobStartTime Then \"Yes\" else \"No\"\n</code></pre> <p>The <code>when</code> section of your test specification would look like this:</p> <pre><code>{\n    \"given\": [\n        ...\n    ],\n    \"when\": {\n        \"data_intg_flow_ref\": \"blah-blah-blah\",  \n        \"parameters\": {\n            \"DSJobStartDate\": \"2012-01-15\",\n            \"DSJobStartTime\": \"11:05:01\"\n        }\n    },\n    \"then\": [\n        ...\n    ]\n}\n</code></pre> Be careful when using multiple date/time macros <p>Exercise caution when setting <code>DSJobStartTimestamp</code> in conjunction with either <code>DSJobStartDate</code> or <code>DSJobStartTime</code> as the DataStage test case capability does not attempt to enforce logical consistency between these parameters. i.e. You could specify conflicting values for these macros which would create a contradictory logical condition. e.g. <pre><code>{\n    \"when\": {\n        \"data_intg_flow_ref\": \"blah-blah-blah\",  \n        \"parameters\": {\n            \"DSJobStartTimestamp\": \"2025-02-03 00:00:00\", \n            \"DSJobStartDate\": \"2024-04-05\"\n            \"DSJobStartTime\": \"09:30:00\"\n        }\n    }\n}\n</code></pre></p>","tags":["DATASTAGE","TESTING"]},{"location":"pipelines/","title":"Introduction","text":"<p>The latest version can always be found here: https://pages.github.ibm.com/datamigrators/devops-for-datastage/</p> <p>Download the latest (PDF) Download the latest (DOCX)</p> <ul> <li> <p> Set up in 5 minutes</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p> </li> <li> <p> Open Source, MIT</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p> </li> </ul>"},{"location":"testing/baselining-test-results/","title":"Recapture a test result baseline","text":"<p>As the logic of your flow changes, so the test data files representing your desired output will also need to change.  DataStage\u00ae can automatically re-baseline your expected output based on an execution of your DataStage job.  Note that while this process is similar to the process described in Capturing test data this process differs in that it only captures the output(s) of your job.</p> <p></p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/baselining-test-results/#process","title":"Process","text":"<ol> <li>In the test case editor, open the Test data in use tree and select the test output file(s) you want to re-baseline.</li> <li>In the data area above the table click the trash icon to delete the data file.</li> <li>Your test specification now refers to at least one CSV data file which no longer exists. Execute your test case without changing the specification. DataStage will identify that no expected results exist for the file(s) you\u2019ve deleted and re-create them using the data captured at runtime.  Note that test case will fail when executed in this mode.</li> <li>Re-execute the same test case job.  DataStage will now use the new baseline results files and your test case will pass.</li> </ol>","tags":["DATASTAGE","TESTING"]},{"location":"testing/capturing-test-data/","title":"Capturing test data","text":"<p>Each DataStage\u00ae development team will already have a set of test data that they use to verify their flow's correct operation.  DataStage\u00ae enables you to capture that data (regardless of whatever technology is currently used to supply it) and encapsulate it into a commonly managed, well governed artefact which can travel with your flow to repeatedly assert its consistent behavior in any downstream environment.  This existing test data can be captured by DataStage by running a flow in 'Data Capture' mode.</p> <p></p> <p>This process involves running your flow in a 'Capture' mode.  In this mode DataStage will interrogate the data flowing along the input and output links referenced in your test case specification and record the data it observes into the test data file defined (by your specification) for each link.  This permits the capture of structured and unstructured data from both batch and streaming data sources.</p> <p>The data flowing along a flow's output links is captured as the current definition of 'expected' output into the relevant output data files.  When you alter the flow's functionality you may well need to re-capture a new baseline of expected results.</p>","tags":["DATASTAGE","TESTING","CAPTURE"]},{"location":"testing/capturing-test-data/#process","title":"Process","text":"<ol> <li>In the test case editor click Capture data. You'll need to accept any 'Overwrite all test data' warnings you receive by clicking the Capture data button.</li> <li>You'll receive a message telling you the flow is running.  Select the Test history tab to browse the most recent history of test case job invocations, including jobs currently in progress.</li> <li>Once the job is complete select the Data tab and browse the newly-populated test data under the the Test data in use tree.</li> </ol>","tags":["DATASTAGE","TESTING","CAPTURE"]},{"location":"testing/configuring-test-data-storage/","title":"Configuring test data storage","text":"","tags":["DATASTAGE","TESTING"]},{"location":"testing/configuring-test-data-storage/#create-a-connection","title":"Create a connection","text":"<p>Start by creating a connection to a storage volume where test assets will be stored.</p> <ol> <li>From the CPD Cluster home page open an existing project or create a new project then, on the Assets tab, click New Asset &gt; Connect to a data source.</li> <li>On the resulting page select Storage volume and Next.</li> <li>On the Create connection: Storage volume page give your new connection a name and optional description.</li> <li>Select an available storage volume. If you don't already have an storage volume available \u2026</li> <li>click New volume.</li> <li>Select a namespace (the default will be fine).</li> <li>Give your storage volume a name and optional description.</li> <li>Select your preferred storage type and click Add.</li> <li>Under Personal credentials &gt; Input method select Enter credentials manually.</li> <li>Check the Use my platform login credentials then click Test connection.</li> <li>Assuming you have a successful connection, click Save.</li> </ol> <p>For more details see Adding connections to data sources in a project.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/configuring-test-data-storage/#add-the-connection-to-your-project-settings","title":"Add the connection to your project settings","text":"<p>Now you'll configure DataStage\u00ae to use your storage volume for storing test case assets.</p> <ol> <li>From the CPD Cluster home page select the Manage tab then, under Tools, select DataStage and then select the tab Test cases.</li> <li>For Test data connection type select Storage Volume.</li> <li>For Test data storage select the name of the Storage volume you created in the step above.</li> <li>For Default DataStage Test case job suffix specify a suffix which will be appended to all test case jobs to help distinguish them in the job log from invocations of their associated flows. e.g. <code>Test Case Job</code>. Note that a leading space has been included here as DataStage will not automatically add one for you.</li> </ol>","tags":["DATASTAGE","TESTING"]},{"location":"testing/creating-datastage-test-cases/","title":"Creating a DataStage test case","text":"<p>Unit tests can be created for DataStage\u00ae flows using the DataStage user interface.  When DataStage creates a test case it performs the following steps:</p> <ol> <li>Inspect your flow design to identify all source and target stages.</li> <li>Read the metadata definition of each source stage input link and target stage output link (i.e. all data flowing into and out of your flow).  Note that each source stage may be configured with multiple output links, and each target stage may be configured with multiple input links.</li> <li>Create an empty test case data file for each source and target link, with appropriate metadata definitions.</li> <li>Interrogate your flow's parameters.</li> <li>Create a test case specification which provides references to all of your flow's parameters as well as each newly-created test data file.</li> </ol> <p></p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/creating-datastage-test-cases/#process","title":"Process","text":"<p>You can create DataStage test cases either as a new asset or directly from within the DataStage designer canvas.</p> <p>From the CPD Cluster home page open an existing project or create a new project then, on the Assets tab, click New Asset &gt; Create reusable DataStage components &gt; Test case.</p> <p>To edit a test case from the DataStage canvas, go to an existing or new flow and click the Test cases icon to open up the test cases panel. Click New test case.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/creating-datastage-test-cases/#defining-test-case-properties","title":"Defining test case properties","text":"<ol> <li>On the Create test case page specify the name and optional description for the DataStage test case.  If you invoked this action when creating a new asset you'll also need to specify a DataStage flow with which to associate this test case.</li> <li>Click Next.</li> <li>On the Select stubbed links page select the flow links which will be stubbed in the test. This determines the \u2026<ul> <li>input links into which test data will be injected, and</li> <li>output links from which data will be compared to the expected output.</li> </ul> </li> <li>Click Next</li> <li>Specify the names of parameters or parameter sets for which your test will supply hard-coded values.</li> <li>Click Create.</li> </ol>","tags":["DATASTAGE","TESTING"]},{"location":"testing/creating-datastage-test-cases/#creating-test-data","title":"Creating test data","text":"<p>There are a number of ways you can derive data for your test case.  Start by opening you test case and from the Data tab selecting the test data file you wish to edit.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/creating-datastage-test-cases/#capture-test-data","title":"Capture test data","text":"<p>Use this method to capture data at runtime from a job invocation.  For more details see Capturing test data.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/creating-datastage-test-cases/#import-test-data","title":"Import test data","text":"<p>You can import locally-stored CSV data into your IBM Cloud Pak DataStage test data files:</p> <ol> <li>Click the Import button above the test data table.</li> <li>Upload your file by dragging and dropping your file, or clicking the link to specify a file.</li> <li>Click Import.</li> </ol> <p>Note that any existing test data in your selected file will be overwritten.</p> <p>You can read more about supplying the data and parameters that define your tests in editing DataStage test cases.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/editing-datastage-tests/","title":"Editing a DataStage test case","text":"<p>You can enter the DataStage\u00ae test cases editor either by selecting the Test case asset on the project page or from within the DataStage designer canvas.</p> <ul> <li>Open an existing project then open the Assets tab and under the Asset types panel select DataStage components &gt; Test cases from where you can click the name of the test case you wish to edit.</li> <li>From the DataStage canvas open an existing DataStage flow then click the Test cases icon to open up the test cases side panel from where you can click the name of the test case you wish to edit.</li> </ul> <p>This will bring you to the test case editor which allows you to inspect and modify your test case specification as well as edit the contents of your input and output test data files.</p> <p></p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/editing-datastage-tests/#editing-the-test-case-specification","title":"Editing the test case specification","text":"<p>Selecting Specification from the Data tab will display the test case's specification.</p> <p>For a detailed explanation of the format of this JSON specification and the options available for controlling how your test case behaves see Test specification format.</p> <p>Each test data file referenced in your JSON specification (whether it represents input data or expected output data) will appear as a file under the Test data in use tree.  Selecting one of these will enable you to view and edit the test data.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/editing-datastage-tests/#editing-test-data","title":"Editing test data","text":"<p>As well as using capture and import methods to derive test data, you can also manually enter test data into your test data files.  The test data table can be edited interactively like a spreadsheet and provides the following notable capabilities:</p> <ul> <li>Undo/redo of editing actions is supported with the traditional keyboard shortcuts Control-Z and Shift-Control-Z (Windows) or Command-Z and Shift-Command-Z (macOS).</li> <li>Values entered into a cell are validated based on the column's metadata definition. Invalid data is highlighted in red.</li> </ul>","tags":["DATASTAGE","TESTING"]},{"location":"testing/editing-datastage-tests/#modifying-metadata","title":"Modifying metadata","text":"<ul> <li>Rows can be added by selecting the Add row icon above the test data table.</li> <li>Rows can be deleted by selecting the three dots on the row header and clicking Delete.</li> <li>Columns can be added by selecting the Add column icon above the test data table.</li> <li>Columns can be deleted by selecting the three dots on the column header and clicking Delete column.</li> </ul> <p>Modify the metadata of a test data column by selecting the three dots on the column header and clicking Edit column.  The resulting panel enables you to specify the column's name, data type, nullability, length, and extended metadata. Click Save to record your changes.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/editing-datastage-tests/#modifying-test-data-outside-the-datastage-interface","title":"Modifying test data outside the DataStage interface","text":"<p>You can export IBM Cloud Pak DataStage test data files to locally-stored CSV files for offline editing:</p> <ol> <li>Click the menu overflow (V) button above the test data table to reveal more options and click Download .</li> <li>Modify the local filename as required and click Download.  The resulting CSV file will be downloaded to your browser's default download location.</li> </ol> <p>Once edited you can re-import your updated by clicking the Import button above the test data table and specifying your edited file before clicking Import.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/editing-datastage-tests/#managing-test-cases","title":"Managing test cases","text":"","tags":["DATASTAGE","TESTING"]},{"location":"testing/editing-datastage-tests/#rename-a-test-case","title":"Rename a test case","text":"<p>You can rename a test case from the asset browser by moving your pointer over the test case name and clicking the edit icon which appears alongside it. Editing the name in the table cell and press the Return key or click the green checkmark to save your changes.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/editing-datastage-tests/#delete-a-test-case","title":"Delete a test case","text":"<p>You can delete a test case from the asset browser by clicking the 'three dots' icon of the test case name and selecting Delete.  On the resulting dialog verify the relationships of the asset you're deleting and click Delete to confirm.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/editing-datastage-tests/#save-changes","title":"Save changes","text":"<p>Once you're happy with your test data changes you can store your changes by clocking the Save button on the test data editor toolbar.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/editing-datastage-tests/#export-a-test-case","title":"Export a test case","text":"<p>Export a test case to a zip file by clicking the Export icon on the test case toolbar.  On the resulting dialog confirm the name of the export file and click Download.  Note that this export does not contain test data.  To export test data for external modification see Modifying test data outside the DataStage interface above.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/editing-datastage-tests/#test-case-settings","title":"Test case settings","text":"<p>Click the Settings icon to open the test case settings panel which enables you to specify options for the selected test.</p> <p>History record storage allows you to specify the number of historical test results you wish to retain. This can be specified either by the number of days or the number of runs.</p> <p>Schedule allows you to specify a time and date when you want your test case job to be automatically executed and (optionally) the frequency with which the job should be re-executed.</p> <p>Click Save to store your selections.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/excluding-columns-from-tests/","title":"Excluding columns from tests","text":"<p>You can omit selected columns from the test case output comparison by adding the columns to be ignored to an <code>ignore</code> array in the relevant specification's <code>then</code> property.</p> <pre><code>{\n    \"then\": [\n        {\n            \"path\": \"ODBC_orders.csv\",\n            \"stage\": \"ODBC_order\",\n            \"link\": \"order_out\",\n            \"ignore\": [\n                \"Creation_date\",\n                \"Last_updated\"\n            ]\n        }\n    ]\n}\n</code></pre> <p>Note: Ignoring columns will prevent columns containing non-deterministic from affecting test results but will also omit those columns from test comparisons, so unexpected output in those columns, or changes in the output of those columns, will not be detected by your test case.  This reduces your test coverage and should be avoided if possible. A common technique to avoid non-deterministic outputs is to ensure all inputs data sources and flow parameters are stubbed by your test specification.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/executing-datastage-test-cases/","title":"Executing a DataStage test case","text":"<p>You can execute DataStage\u00ae test cases either from the CPD Cluster home page, the DataStage designer canvas, or the DataStage test case editor.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/executing-datastage-test-cases/#from-the-cpd-cluster-home-page","title":"From the CPD Cluster home page","text":"<ol> <li>Open an existing project and select the Jobs tab.</li> <li>Click the name of the test case you wish to invoke.  This will display the job details panel.</li> <li>Click the Run job button in the job details toolbar to invoke the test.</li> <li>When the status icon shows your test has completed click the timestamp to see test results.</li> </ol>","tags":["DATASTAGE","TESTING"]},{"location":"testing/executing-datastage-test-cases/#from-the-datastage-canvas","title":"From the DataStage canvas","text":"<ol> <li>Open an existing DataStage flow for which you have created a test case.</li> <li>Click the Test cases icon to  open up the test cases side panel.</li> <li>Click the Run icon alongside the name of the test case you wish to invoke.</li> <li>When the status icon shows your test has completed click the timestamp to see test results.</li> </ol>","tags":["DATASTAGE","TESTING"]},{"location":"testing/executing-datastage-test-cases/#from-the-datastage-test-case-editor","title":"From the DataStage test case editor","text":"<ol> <li>Open an existing test case.</li> <li>Click the Run button on the toolbar to invoke your test.</li> <li>Click View result on the notification that appears when your job is complete.</li> </ol> <p>Once your test is complete you should verify your test results.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/executing-datastage-test-cases/#background","title":"Background","text":"<p>When DataStage executes your test case it will dynamically replace your flow's input stages at runtime with components which inject data from the relevant CSV data files into your job on the links specified in your test specification.  Any source data repositories (files, databases, etc.) included in your test specification will not be connected to or read during a test case execution.</p> <p>Similarly, your flow's output stage(s) will be replaced at runtime with components which read the incoming data and compare it to the relevant CSV data files containing the output expected on those links.  Any differences are reported in the test results.</p> <p></p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/high-volume-tests/","title":"High Volume DataStage Tests","text":"<p>During the execution of a DataStage\u00ae test case the data produced by a job (on one or more output links) is compared against expected test data to identify and report on any differences.  When testing with large volumes of data, the comparison process may consume too much memory and cause your test job to abort with a fatal error.  The simplest approach to resolving this issue is to reduce your test data volume to the smallest number of records necessary to exercise each code path through your flow.  Doing so will ensure that your test cases execute quickly and can be easily understood and maintained.</p> <p>In the event that test data available to you cannot easily be reduced, the memory required by the data comparison process can be reduced by specifying a Cluster Key in the test specification.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/high-volume-tests/#using-cluster-keys-in-datastage-tests","title":"Using Cluster Keys in DataStage Tests","text":"<p>Defining a Cluster Key will cause DataStage to split the actual data output and expected data into multiple, smaller subsets before the data is compared.  Data is split such that each subset will only contain records that have the same values for all columns that make up the Cluster Key - a process somewhat analogous to DataStage partitioning.  The data are then sorted and a comparison of actual and expected data is performed using multiple, smaller operations which require less memory and are performed sequentially.  </p> <p>Test result behavior: Due to the iterative nature of comparisons using a Cluster Key, each record which has differences in the Cluster Key columns will be reported as 1 added record and 1 removed record rather than shown as a single record with a change indicator.</p> <p>A good Cluster Key is one that results in data subsets which strike a balance between the following factors:</p> <ul> <li>Each subset should fit in memory during comparison. Test execution will abort when memory thresholds are breached.</li> <li>Are as large as possible given the memory constraint. Lots of tiny subsets will degrade comparison performance.</li> </ul> <p>Selecting an appropriate Cluster Key might require several iterations to find a column (or combination of columns) which not only prevents Job aborts but also keeps run times acceptable.  Unless you are comparing unusually wide records, a good starting point is to aim for each subset of data to contain no more than 1,000 records and adjust the Cluster Key if memory thresholds continue to be breached.</p> <p>If you have used Interception to capture some input and / or expected test data for a DataStage Test and subsequently decide you want to apply a Cluster Key, you don\u2019t have to re-run Interception. This is also the case if you\u2019ve manually created any test data files. The Cluster Key is used at run time and therefore doesn\u2019t require any additional data preparation by the user.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/high-volume-tests/#example","title":"Example","text":"<p>Consider the situation where a DataStage Test has to compare several million financial transaction records with the following schema on the 'order_out' link of stage 'ODBC_order':</p> Column name SQL type Length Scale Nullable Transaction_Date Timestamp No Account_Id VarChar 20 No Type_Code VarChar 5 No Description VarChar Yes Amount Decimal 18 2 No <p>The test specification can be updated with a Cluster Key to enable iterative comparison of actual and expected test data.  In this example, <code>Account_Id</code> and <code>Type_Code</code> are defined as the compound Cluster Key:</p> <pre><code>{\n    \"then\": [\n        {\n            \"path\": \"ODBC_orders.csv\",\n            \"stage\": \"ODBC_order\",\n            \"link\": \"order_out\",\n            \"cluster\": [\n                \"Account_Id\",\n                \"Type_Code\"\n            ]\n        }\n    ],\n}\n</code></pre> <p>Note: Cluster Keys are specified on a per-link basis. DataStage flows with multiple output links can use any combination of clustered and non-clustered comparisons within a single test specification.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/high-volume-tests/#caveats","title":"Caveats","text":"<p>Cluster keys should be chosen to break Actual and Expected data into clusters which are small enough to fit in memory.</p> <p>Note that if a Unit Test detects a value difference in a column which is a cluster key column, then the Unit Test difference report (which would normally describe the difference as a \u2018modified\u2019 row when not using a cluster key) will now describe the difference as distinct \u2018added\u2019 and \u2018removed\u2019 entries.  </p> <p>As useful as Cluster Keys are, it\u2019s poor practice to simply apply them to every DataStage test that has to process high data volumes. You will almost certainly find combinations of flows and data volumes in your project where no Cluster Key will reduce the memory demands of a DataStage test enough to avoid Job aborts (See Unit Test throws OutOfMemoryError exception). In these situations you can manage your test data volumes by \u2026</p> <ul> <li>carefully selecting a subset of records from your data sources,</li> <li>using the DataStage's data fabrication features, or</li> <li>both of these approaches in combination.</li> </ul>","tags":["DATASTAGE","TESTING"]},{"location":"testing/migrating-datastage-tests-from-older-versions/","title":"Migrating test cases from older versions of DataStage","text":"<p>Users of IBM\u00ae DataStage\u00ae v11.x who built DataStage unit tests using MettleCI will be familiar with the YAML syntax used to specify those unit tests. Test cases for Cloud Pak DataStage are different in that they are specified using JSON rather than YAML.  Despite this syntactic difference, the options and structure of a test specification remain identical.</p> <p>Existing MettleCI unit tests are easily migrated into DataStage on Cloud Pak for Data using the <code>mettleci unittest migrate</code> command available in the MettleCI command line.  The documentation for this command describes the process you need to undertake to safely migrate your tests to Cloud Pak.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/row-count-comparisons/","title":"Row count comparisons","text":"<p>You can configure a DataStage\u00ae test case to only compare outputs' row counts, rather than the content of those rows, by setting the <code>checkRowCountOnly</code> property to true.</p> <pre><code>{\n    \"then\": [\n        {\n            \"path\": \"ODBC_orders.csv\",\n            \"stage\": \"ODBC_order\",\n            \"link\": \"order_out\",\n            \"checkRowCountOnly\": true\n        }\n    ],\n}\n</code></pre> <p>Note that the <code>checkRowCountOnly</code> property takes a boolean value which does not use quotes.</p> <p>The test case report containing a single cell comparing the expected and actual output row count (of the form <code>Expected-&gt;Actual</code>.)</p> <p></p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/selective-stubbing/","title":"Selective stubbing","text":"<p>The process of 'stubbing' involves using a fabricated version of an external data source (a 'stub') that returns specific, deterministic values or behaviors. Stubs can be used to test code that relies on external data sources that are not available at a given time or in a given environment, or which are non-deterministic.</p> <p>When you specify a DataStage\u00ae unit test you are defining stub data and telling DataStage which link(s) to stub with that data. There may be some instances where you wish to define a test case that only injects test data into some of your flow's input links, and allow other source stages to operate normally during a test execution. These input links which are not stubbed are not referenced in your test specification and will connect to their configured data source and retrieve data at runtime.</p> <p>To define a link which should not be stubbed simply omit the link from the <code>given</code> section of your test specification.</p> <p>For example \u2026</p> <pre><code>{\n    \"given\": [\n        {\n            \"path\": \"filePurchasesIn.csv\",\n            \"stage\": \"dsEX_Purchase\",\n            \"link\": \"inPurchase\" \n        }\n    ],\n    \"then\": [\n        {\n            \"path\": \"filePurchasesOut.csv\",\n            \"stage\": \"dsTR_Purchase\",\n            \"link\": \"outPurchase\"\n        }\n    ],\n    \"when\": {\n        \"data_intg_flow_ref\": \"blah-blah-blah\",  \n        \"parameters\": {\n        }\n    }\n}\n</code></pre> <p> </p> <p>Note: When defining test cases that use selective stubbing you should to exercise caution when deploying those test cases to downstream test environments.  Those environments will need to be configured to permit stages which have not been stubbed to retrieve data from their configured data sources.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/test-datastage-sparse-lookup-stages/","title":"Test Cases with sparse lookups","text":"<p>Note: This page is specific to sparse lookups.  Lookup stages configured to use normal lookups do not need any special considerations for DataStage unit testing.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/test-datastage-sparse-lookup-stages/#using-a-sparse-lookup-explicit-test-method","title":"Using a sparse Lookup ('Explicit' test method)","text":"<p>When designing DataStage flows using a lookup stage you configure the lookup to operate in normale or sparse mode by changing the lookup Lookup type in the Output tab of the database stage providing  the lookup reference.  When a DataStage flow featuring a sparse lookup is compiled executed, however, the  lookup stage is not used to perform the sparse lookup.  Instead, DataStage replaces the lookup stage with  the database operator which is responsible for reading input rows, looking up values from the database,  and producing output records.  It is for this reason that all database log messages in the DataStage Director  are attributed to the Lookup stage and why the Database stage never appears in the Monitor of the DataStage Director.</p> <p>Open image-20200129-024550.png</p> <p>To Unit Test job designs using Sparse Lookup stages the sparse lookup functionality needs to be explicitly  replaced with user-supplied Unit Test data:</p> <p>Open image-20221116-231138.png</p> <p>The most explicit way to configure Unit Testing to replace a Sparse Lookup with Test data is by adding the input  link to the then (expected outputs) clause of the Unit Test Spec and the output link to the given (supplied inputs)  clause of the Job\u2019s Unit Test Specification.  </p> <p>The CSV file specified in the then clause contains the data that will be be compared to the data flow of records arriving  at the input of the Sparse Lookup stage.  The data should describe what records are expected to be used to provide the  sparse  lookup\u2019s key columns.</p> <p>The CSV file specified in the given clause contains the data that will be become the data flow of records from the output  of the Sparse Lookup stage.  The data should simulate what would be produced by the real Sparse Lookup Stage if it had  actually processed the Unit Test input records against the real database reference source, however they don't have to.</p> <p>Open image-20200129-014439.png</p> <pre><code>given:\n  - stage: SparseLookup\n    link: Output\n    path: SparseLookup-Output.csv\nwhen:\n...\nthen:\n  - stage: SparseLookup\n    link: Input\n    path: SparseLookup-Input.csv\n</code></pre> <p>Open image-20200129-014525.png</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/test-datastage-sparse-lookup-stages/#sparse-lookup-stage-replace-method","title":"Sparse Lookup Stage ('Replace' method)","text":"<p>MettleCI Unit Test Harness version 1.1-379 and later provides a convenient alternative capability which uses the new Unit Test Specification spareseLookup and associated key clauses to replace the entire Sparse Lookup stage with Test Data while only requiring the user to supply Test Data for the reference link:</p> <p>Open image-20200129-014439.png</p> <p><pre><code>given:\n  - sparseLookup: SparseLookup\n    path: Database-Reference.csv\n    key:\n      - KEY_COLUMN_1\n      - KEY_COLUMN_2\n...\n\nOpen image-20221116-232511.png\n\n \n\nIn this mode the Sparse Lookup stage is replaced entirely with a Unit Test version of the sparse lookup which uses the specified Test Data as the lookup data.  It is provided as a convenient alternative to explicitly replacing Sparse Lookup stage input and output links, allowing the remaining logic in the job to be tested while not actually testing the behaviour of DataStage\u2019s Sparse Lookup stage.  \n\nWhen generating Unit Tests from Job designs containing Sparse Lookups, MettleCI Workbench version 1.0-1483 and later will automatically apply this Unit Test pattern and generate test specifications which replace Sparse Lookup stages entirely.\n\n## Known Limitations\n\nReplacing the Sparse Lookup stage with a Unit Test version of the sparse lookup comes with some limitations that DataStage developers should keep in mind.  \n\nUnit Test Sparse Lookup stages simulate typical key matching and assumes data equality with three-valued-logic semantics.  Custom key-matching logic embedded in custom lookup SQL (eg. SQL with a where clause like where KEY_COLUMN=Upper(ORCHESTRATE.KEY_COLUMN)) will not be replicated.\n\nWhen running Unit Testing in Interception mode, one additional Sort operation per Unit Test Sparse Lookup stage is required.  For sparse lookup stages which produce large volumes of output data this can have an adverse affect on job execution times when running in Interception mode.\n\nReference data records that contain Nulls or Default Values for all columns are ignored during interception when the Sparse Lookup stage is set to Continue on Lookup Failure.  This will have no functional impact on the output of the Sparse Lookup Stage and is expected behaviour.\n\nWhere you consider these limitations unacceptable you can revert to the original (explicit) method for replacing Sparse Lookups.\n\nA pragmatic approach for Multiple Sparse Lookups\nFor jobs where the vast majority of job logic is implemented using Sparse Lookup stages, replacing all lookups with Unit Test data would result in little-to-no DataStage logic being tested (as illustrated below).  \n\nOpen image-20200129-035608.png\n\nFor the type of Job design show above, a traditional explicit testing approach would necessitate the developer providing 8 sets of test data! An alternative testing approach is to leave the Sparse Lookups in place and replace only the input and output stages with Unit Test data.  A live Database connection will be required during testing but the when clause can be used to set job parameters that dictate database connection settings. \n\nTechnically this is an Integration Test, not a Unit Test: The Unit Test Harness does not provide any functionality for populating database reference tables with Unit Test data prior to test execution, users are responsible for managing Integration Test setup and tear down through governance and/or CI/CD pipeline customisation.\n\nOpen image-20200129-040758.png\n\n \n</code></pre> given:   - stage: Source     link: Input     path: Source-Output.csv when:   parameters:     DbName: MyUnitTestDb     DbUser: MyUnitTestUser     DbPass: {iisenc}dKANDae233DJIQeiidm== then:   - stage: Target     link: Output     path: Target-Output.csv ```</p> <p>Open image-20200129-040641.png</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/test-specification-format/","title":"DataStage test specification format","text":"<ul> <li>Structure overview</li> <li>Given these inputs</li> <li>Sparse Lookup sources</li> <li>When these conditions are met</li> <li>Then expect these outputs</li> </ul>","tags":["DATASTAGE","TESTING"]},{"location":"testing/test-specification-format/#structure","title":"Structure","text":"<p>A DataStage\u00ae test case specification (often abbreviated \u2018Spec') is a JSON-formatted file which uses a grammar modelled loosely on the Gherkin syntax used by the Cucumber testing tool. The overall structure follows the common Gherkin pattern \u2026</p> <pre><code>{\n    \"given\": [\n        { This test data on input link 1 },\n        { This test data on input link 2 }\n    ],\n    \"when\": {\n        I execute the test case with these options and parameter values\n    },\n    \"then\": [\n        { Expect this data to appear on output link 1 },\n        { Expect this data to appear on output link 2 }\n    ]\n}\n</code></pre> <p>Note: The user interface may order the JSON objects alphabetically (<code>given</code> &gt; <code>then</code> &gt; <code>when</code>) but this has no effect on the functionality of the test.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/test-specification-format/#given","title":"Given","text":"<p>The <code>given</code> property array associates test data files with your flow's input , thereby defining the test values you wish to inject into your flow's inputs at runtime.</p> <p>For example:</p> <pre><code>{\n    \"given\": [\n        {\n            \"path\": \"fileCustomers.csv\",\n            \"stage\": \"sfCustomers\",\n            \"link\": \"Customers\" \n        },\n        {\n            \"path\": \"fileOrders.csv\",\n            \"stage\": \"sfOrders\",\n            \"link\": \"Orders\"\n        }\n    ],\n}\n</code></pre> <p>Some source stages can be configured with multiple output links so each input in your test specification's <code>given</code> property array is uniquely identified using a combination of the stage and link names to eliminate ambiguity.  The array also contains a <code>path</code> property to identify the test data CSV file containing the test data that is to be injected on each incoming link.</p> <p>Note that not every stage in a job must be provided with test data.  You can easily craft a test specification which uses test data for only a subset of flow stages.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/test-specification-format/#sparse-lookup-sources","title":"Sparse Lookup sources","text":"<p>When an input source is used with a Sparse Lookup stage then rather than using the stage property to specify the input you will use the <code>sparseLookup</code> property.</p> <p>For example:</p> <pre><code>{\n    \"given\": [\n        {\n            \"path\": \"fileCustomers.csv\",\n            \"stage\": \"sfCustomers\",\n            \"link\": \"Customers\" \n        },\n        {\n            \"sparseLookup\": \"SparseLookup\",\n            \"path\": \"Database-Reference.csv\",\n            \"key\": [\n                \"KEY_COLUMN_1\",\n                \"KEY_COLUMN_2\"\n            ]\n        }\n    ],\n}\n</code></pre> <p>The <code>sparseLookup</code> property identifies a JSON object which specifies \u2026</p> <ul> <li>the value defining the name of the sparse lookup reference stage,</li> <li>a path to the relevant CSV test data file, and</li> <li>a list of key columns to be used for the sparse lookup.</li> </ul>","tags":["DATASTAGE","TESTING"]},{"location":"testing/test-specification-format/#when","title":"When","text":"<p>The <code>when</code> property array specifies which job will be executed during testing as well as any parameters (including job macros) that affect the data produced by the job.</p> <p>For example, this specification will</p> <p>Substitute hardcoded values for the <code>DSJobStartDate</code> and <code>DSJobStartTime</code> macros and the <code>paramStartKey</code> parameter:</p> <pre><code>{\n    \"when\": {\n        \"data_intg_flow_ref\": \"3023970f-ba2dfb02bd3a\",  \n        \"parameters\": {\n            \"DSJobStartDate\": \"2012-01-15\",\n            \"DSJobStartTime\": \"11:05:01\",\n            \"paramStartKey\": \"100\"\n        }\n    },\n}\n</code></pre> <p>One application of the <code>parameters</code> property is to supply values to make flows that rely on system date and time information produce a deterministic output by hard coding those values when testing.</p> <p>Note that the <code>data_intg_flow_ref</code> property is an internally-generated DataStage reference to the flow with which this test is associated and should not be changed.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/test-specification-format/#then","title":"Then","text":"<p>The <code>then</code> property array associates test data files with your flow's output links.</p> <pre><code>{\n    \"then\": [\n        {\n            \"path\": \"ODBC_customers.csv\",\n            \"stage\": \"ODBC_customer\",\n            \"link\": \"customer_out\"\n        },\n        {\n            \"path\": \"ODBC_orders.csv\",\n            \"stage\": \"ODBC_order\",\n            \"link\": \"order_out\"\n        }\n    ],\n}\n</code></pre> <p>Similar to the <code>given</code> property, because some target stages can be configured with multiple input links the test specification's <code>then</code> property array uniquely identifies links using a combination of the stage and link names. The array also contains a <code>path</code> property to identify the test data CSV file containing the expected test output that will be compared to the actual data appearing on each outgoing link.</p> <p>Other properties which extend the capabilities of your test case can be included in the <code>then</code> property array:</p> <ul> <li>The <code>ClusterKey</code> property: Improve performance of test cases when using data volumes</li> <li>The <code>checkRowCountOnly</code> property: Configure your tests to only count the number of rows</li> <li>The <code>ignore</code> property: Exclude specific columns from test comparisons</li> </ul>","tags":["DATASTAGE","TESTING"]},{"location":"testing/testing-datastage-flows/","title":"Getting Started With Testing DataStage Flows","text":"<p>DataStage\u00ae test cases are design-time assets that use data files to define the inputs and expected outputs of your DataStage flows.</p> <p>The basic building blocks of a test case are:</p> <ul> <li>A test specification</li> <li>One or more test data input files</li> <li>One or more test data output files</li> </ul> <p>Each DataStage test case is associated with a single DataStage flow. You can create DataStage test cases as a new asset or directly from within the DataStage designer canvas.  A DataStage test case is executed by a job in a manner similar to its associated DataStage flow. During execution the input data files are injected into your flow's incoming links and the data appearing on the output links are compared to the output files containing the expected outputs. Any differences in the two will cause the test to fail and the differences to be reported alongside the test case's job log.  </p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/testing-datastage-flows/#using-datastage-test-cases","title":"Using DataStage test cases","text":"<ol> <li>Configuring test data storage</li> <li>Creating DataStage test cases</li> <li>Editing DataStage tests</li> <li>Executing DataStage tests</li> <li>Verifying DataStage test results</li> <li>Migrating test cases from older versions of DataStage</li> </ol>","tags":["DATASTAGE","TESTING"]},{"location":"testing/troubleshoot-testing/","title":"Troubleshooting","text":"Problem Resolution I've modified my flow design and my test no longer passes Create a new test result baseline. The test case editor display the following message:<code>No connection has been defined on the project. Some features may be limited.</code> Configure a connection to store your test data.","tags":["DATASTAGE","TESTING"]},{"location":"testing/troubleshooting/","title":"Troubleshooting","text":"Problem Resolution I've modified my flow design and my test no longer passes Create a new test result baseline. The test case editor display the following message:<code>No connection has been defined on the project. Some features may be limited.</code> Configure a connection to store your test data.","tags":["DATASTAGE","TESTING"]},{"location":"testing/verifying-test-results/","title":"Verifying test results","text":"<p>You can verify DataStage\u00ae test results either from the CPD Cluster home page, the DataStage designer canvas, or the DataStage test case editor.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/verifying-test-results/#from-the-cpd-cluster-home-page","title":"From the CPD Cluster home page","text":"<ol> <li>Open an existing project and select the Jobs tab.</li> <li>Click the name of the test case you wish to inspect.  This will display the job details panel.</li> <li>Click the timestamp of a test to see its results.</li> </ol>","tags":["DATASTAGE","TESTING"]},{"location":"testing/verifying-test-results/#from-the-datastage-canvas","title":"From the DataStage canvas","text":"<ol> <li>Open an existing DataStage flow for which you have created a test case.</li> <li>Click the Test cases icon to open up the test cases side panel.</li> <li>Click the timestamp of a test to see its results.</li> </ol>","tags":["DATASTAGE","TESTING"]},{"location":"testing/verifying-test-results/#from-the-datastage-test-case-editor","title":"From the DataStage test case editor","text":"<ol> <li>Open an existing test case and select the Test history tab.</li> <li>Click the timestamp of a test to see its results.</li> </ol> <p>On the resulting Run details page select the Test results tab to see details about your test outcome.  Successful tests will present a simple acknowledgement message:</p> <p></p> <p>Test case errors will produce a difference report detailing how the expected and actual results differ from one another.</p> <p></p> <p>A difference report will be available for each failed test - i.e. each test where the expected and actual results varied.  For DataStage flows with multiple test failures (for multiple stubbed outputs) you can select which difference report to display by selecting the relevant output from the Stubbed link drop down box.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/verifying-test-results/#the-difference-report","title":"The difference report","text":"<p>Every DataStage test case involved the comparison of at least one Actual result set, produced by your Flow, and an associated Expected result set, defined by your test case. The differences in these result sets is expressed in a tabular form which describe, using indicators in row headers, column headers, or cells, the operations that would be required to modify the Expected data to match the Actual data.</p> <p>Taking the example test report above:</p> Change type Indicator Example Inserted rows An additional, unexpected row (for customer 'Ardith Beahan') is present Deleted rows The expected row (for customer 'Doc Brown') is missing Inserted columns An additional, unexpected INTEGER column CENTS was produced Deleted columns The expected TINYINT column MEMBERSHIP was not found Modified column metadata Additional header row A VARCHAR column was renamed from <code>FIRST_NAME</code> to <code>FirstName</code> as indicated by an additional header row Modified cell values A modified value (of the form <code>Expected-&gt;Actual</code>) in the DOLLARS columns for person 'Josianne Mante'","tags":["DATASTAGE","TESTING"]},{"location":"tags/","title":"Labels","text":"<p>Following is a list of relevant tags:</p>"},{"location":"tags/#capture","title":"CAPTURE","text":"<ul> <li>Capturing test data</li> </ul>"},{"location":"tags/#cli","title":"CLI","text":"<ul> <li>Compliance namespace</li> <li>The CLI 'project-cache' directory</li> </ul>"},{"location":"tags/#compliance","title":"COMPLIANCE","text":"<ul> <li>Compliance namespace</li> </ul>"},{"location":"tags/#datastage","title":"DATASTAGE","text":"<ul> <li>MettleCI Command Shell</li> <li>Testing local and shared containers</li> <li>Testing stage rejects</li> <li>Testing stored procedure stages</li> <li>Testing surrogate key generator stages</li> <li>Testing date/time references</li> <li>Recapture a test result baseline</li> <li>Capturing test data</li> <li>Configuring test data storage</li> <li>Creating a DataStage test case</li> <li>Editing a DataStage test case</li> <li>Excluding columns from tests</li> <li>Executing a DataStage test case</li> <li>High Volume DataStage Tests</li> <li>Migrating test cases from older versions of DataStage</li> <li>Row count comparisons</li> <li>Selective stubbing</li> <li>Test Cases with sparse lookups</li> <li>DataStage test specification format</li> <li>Getting Started With Testing DataStage Flows</li> <li>Troubleshooting</li> <li>Troubleshooting</li> <li>Verifying test results</li> </ul>"},{"location":"tags/#pipeline","title":"PIPELINE","text":"<ul> <li>Compliance namespace</li> </ul>"},{"location":"tags/#tags","title":"TAGS","text":"<ul> <li>Compliance namespace</li> </ul>"},{"location":"tags/#testing","title":"TESTING","text":"<ul> <li>MettleCI Command Shell</li> <li>Testing local and shared containers</li> <li>Testing stage rejects</li> <li>Testing stored procedure stages</li> <li>Testing surrogate key generator stages</li> <li>Testing date/time references</li> <li>Recapture a test result baseline</li> <li>Capturing test data</li> <li>Configuring test data storage</li> <li>Creating a DataStage test case</li> <li>Editing a DataStage test case</li> <li>Excluding columns from tests</li> <li>Executing a DataStage test case</li> <li>High Volume DataStage Tests</li> <li>Migrating test cases from older versions of DataStage</li> <li>Row count comparisons</li> <li>Selective stubbing</li> <li>Test Cases with sparse lookups</li> <li>DataStage test specification format</li> <li>Getting Started With Testing DataStage Flows</li> <li>Troubleshooting</li> <li>Troubleshooting</li> <li>Verifying test results</li> </ul>"}]}