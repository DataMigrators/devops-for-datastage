{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>The latest version can always be found here: https://pages.github.ibm.com/datamigrators/devops-for-datastage/</p> <p>Download the latest (PDF) Download the latest (DOCX)</p> <ul> <li> <p> Set up in 5 minutes</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p> </li> <li> <p> Open Source, MIT</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p> </li> </ul>"},{"location":"blog/","title":"Blog","text":""},{"location":"flow-analysis/flow-analysis/","title":"Introduction","text":"<p>The latest version can always be found here: https://pages.github.ibm.com/datamigrators/devops-for-datastage/</p> <p>Download the latest (PDF) Download the latest (DOCX)</p> <ul> <li> <p> Set up in 5 minutes</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p> </li> <li> <p> Open Source, MIT</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p> </li> </ul>"},{"location":"mettleci-cli/command-shell/","title":"MettleCI Command Shell","text":"<p>The MettleCI Command Line Interface is available from either your Windows command line or Unix shell.  It provides one way of accessing MettleCI's build and deployment functions, and supports two different modes of operation: console or command line.  MettleCI commands accept various parameters which can optionally be sourced from a command file.</p>","tags":["DATASTAGE","TESTING"]},{"location":"mettleci-cli/command-shell/#console-mode","title":"Console Mode","text":"<p>To enter console mode start the MettleCI Command Line Interface by entering <code>mettleci</code> (UNIX) or <code>mettleci.cmd</code> (Windows).</p> <pre><code>C:\\&gt; mettleci.cmd\nMettleCI Command Line\n(C)2019 Data Migrators Pty Ltd\nEnter [namespace] [command] {options}\nor 'help', 'exit', or 'quit'.\nmettleci&gt;\n</code></pre> <p>In console mode MettleCI prints a command prompt and waits for a command. Each command is processed without exiting MettleCI. You may need to provide authentication options for a commands which invoke functionality in third party systems.  You can enter help to get assistance, or exit the console mode by entering exit, or quit at the prompt.</p>","tags":["DATASTAGE","TESTING"]},{"location":"mettleci-cli/command-shell/#command-mode","title":"Command mode","text":"<p>In command mode you can enter commands one at a time at your operating system's command line. Start each command (omitting the quotes) with <code>mettleci</code> (unix) or <code>mettleci.cmd</code> (Windows) followed by a namespace and command, then the parameters.</p> <p>Open image2019-10-25_22-51-19.png</p> <p>Some of the available commands (listed below) use IBM DataStage client components, and so are platform specific.  For example, job compilation requires access to Windows-only components, and so will not be supported on Unix environments.  The MettleCI command is followed by a namespace, which groups a collection of build and deployment operations.  Each of these commands accepts a number of mandatory and/or optional parameters. </p> <pre><code>mettleci [namespace] [command] {commandoptions}\n</code></pre> <p>Here's an example of the MettleCI Command Line being used to compile an entire DataStage project (using the 'compile' command provided by the 'datastage' namespace) :</p> <pre><code># Note that the example below uses the line continuation charactere ('\\' on Unix or '^' on Windows)\n# to aid readability, but your mettleci command line can all be on a single line if you prefer \n$&gt; mettleci datastage compile \\\n   -domain test1-svcs.datamigrators.io:59445 \\\n   -server test1-engn.datamigrators.io -project dstage1 \\\n   -username isadmin -password isadminpwd\nAnalyzing assets to compile\nCompilation folder location = C:\\Apps\\command-shell\\log\\compiliation\nAttempting to compile with 4 working threads.\nCompiling DataStage jobs...\n * Compile 'test2-engn.datamigrators.io/dstage1/Jobs/Load/EX_Account.pjb' - COMPLETED\n [SNIP]\n * Compile 'test2-engn.datamigrators.io/dstage1/Jobs/Load/TX_StockHolding.pjb' - COMPLETED\nCompilation complete\n$&gt; \n</code></pre> <p>Note that MettleCI Command Line namespaces, commands, and options are all case sensitive. </p>","tags":["DATASTAGE","TESTING"]},{"location":"mettleci-cli/command-shell/#use-a-password-containing-special-characters","title":"Use a password containing special characters","text":"<p>If the password contains special characters, you will need to wrap it with single or double quote or by using escape characters.</p> Password contains Windows-based Unix-based ! (exclamation) Use password without modification. For example: MyPassword! Wrap password with single quote.  For example: 'MyPassword!' \u201c (double quote) Use escape character . For example: My\u201dPassword Wrap password with single quote.  For example: 'My\"Password' ' (single quote) Wrap password with double quote.  For example: \u201cMy'Password\u201d Wrap password with single quote and use escape character .  For example: 'My'''Password' * (asterisk) Use password without modification. For example: My*Password Wrap password with single quote.  For example: 'My*Password' Wrap password with double quote.  For example: \u201cMy Password\u201d Wrap password with single quote.  For example: 'My Password'","tags":["DATASTAGE","TESTING"]},{"location":"mettleci-cli/command-shell/#using-external-command-files-with-the-mettleci-cli","title":"Using external command files with the MettleCI CLI","text":"<p>MettleCI allows you to define a MettleCI command in a text-based \u2018command file\u2019 and pass the file as parameter to the MettleCI command.  This is accomplished using the '@' command syntax: </p> <pre><code># Here's a typical command file\n$&gt; cat file mycommand.txt\ndatastage\ncompile\n-domain\ntest1-svcs.datamigrators.io:59445\n-username\nisadmin\n-password\nisadminpwd\n-server\ntest1-engn.datamigrators.io\n-project\ndstage1\n# ... and here's how to invoke it\n$&gt; mettleci @mycommand.txt\n</code></pre> <p>Note:</p> <ul> <li>Each element of a command file needs to be on an individual line (i.e. separated by your operating system\u2019s newline ASCII character combination)</li> <li>A command file can only contain the definition of a single MettleCI command</li> <li>You can run the MettleCI Command Line with multiple commands by invoking it with individual command files from a shell script with one command per line. E.g.</li> </ul> <pre><code>#!/usr/bin/env bash\nmettleci @mycommand1.txt\nmettleci @mycommand2.txt\nmettleci @mycommand3.txt\n# etc.\n</code></pre>","tags":["DATASTAGE","TESTING"]},{"location":"overview/","title":"Overview","text":"<p>Start here.</p>"},{"location":"patterns/testing-datastage-containers/","title":"Test Cases with local and shared containers","text":"This patterns is handled automatically for you by DataStage <p>For DataStage flows that use this pattern the DataStage test case creation process will generate an appropriately structured test case specification. This page acts as a reference to explain the structure of the generated JSON test specification.</p> <p>Let's take a simple example of a DataStage test case:</p> <p></p> <p>Containers (both local and shared) complicate this situation as stage names in DataStage are only unique within a given flow or container.  </p> <p>Consider writing a test specification for the following flow, <code>ProcessAccounts</code>, which includes a shared container stage <code>ContainerC1</code> which is itself a reference to the shared container <code>scWriteAccounts</code>:</p> <p>Flow <code>ProcessAccounts</code>: </p> <p>Container <code>scWriteAccounts</code>:  |</p> <p>You might be tempted to create a spec like this \u2026</p> <pre><code>{\n    \"given\": [\n        {\n            \"path\": \"given.csv\",\n            \"stage\": \"sfInput\",\n            \"link\": \"in\" \n        }\n    ],\n    \"when\": {},\n    \"then\": [\n        {\n            \"path\": \"expected.csv\",\n            \"stage\": \"sfOutput\",\n            \"link\": \"out\"\n        }\n    ]\n}\n</code></pre> <p>The resulting Unit Test Spec is ambiguous because the MettleCI Unit Test Harness will not be able to uniquely identify which Unit Test Data file is associated with each sqAccounts stage.  To avoid these sort of issues, the stage properties within Unit Test Specs expect fully qualified stage names.  A fully qualified stage name is prefixed with any relevant parent Container names using the format <code>&lt;container name&gt;.&lt;stage name&gt;</code>.</p> <p>Here\u2019s an example of a fully qualified stage name:</p> <pre><code>{\n    \"given\": [\n        {\n            \"path\": \"given.csv\",\n            \"stage\": \"sfInput\",\n            \"link\": \"in\" \n        }\n    ],\n    \"when\": {},\n    \"then\": [\n        {\n            \"path\": \"expected.csv\",\n            \"stage\": \"subflow_1.sfOutput\",\n            \"link\": \"out\"\n        }\n    ]\n}\n</code></pre>","tags":["DATASTAGE","TESTING"]},{"location":"patterns/testing-datastage-flow-rejects/","title":"Testing flows with rejects","text":"<p>Most DataStage jobs can be tested via MettleCI\u2019s Unit Testing function simply by replacing input and output stages. However, some job designs - while commonplace - will necessitate a more advanced Unit Testing configuration.  The sections below outline MettleCI Unit Test Spec patterns that best match these job designs.</p> This patterns is handled automatically for you by DataStage <p>For DataStage flows that use this pattern the DataStage test case creation process will generate an appropriately structured test case specification. This page acts as a reference to explain the structure of the generated JSON test specification.</p>","tags":["DATASTAGE","TESTING"]},{"location":"patterns/testing-datastage-flow-rejects/#input-stage-with-rejects","title":"Input stage with rejects","text":"<p>The Input stage can be Unit Tested by including both read and reject links in the given clause of the Unit Test Spec.</p> <p>The CSV data specified for the rejects link should contain records that will actually test the flow of records through the reject path(s) of the job.</p>","tags":["DATASTAGE","TESTING"]},{"location":"patterns/testing-datastage-flow-rejects/#flow-design","title":"Flow design","text":"","tags":["DATASTAGE","TESTING"]},{"location":"patterns/testing-datastage-flow-rejects/#test-specification","title":"Test specification","text":"<pre><code>{\n   \"given\": [\n      {\n         \"stage\": \"Input\",\n         \"link\": \"Read\" \n         \"path\": \"Input-Read.csv\",\n      },\n      {\n         \"stage\": \"Input\",\n         \"link\": \"Rejects\" \n         \"path\": \"Input-Rejects.csv\",\n      }\n   ],\n   \"when\": {\n      \"parameters\": { }\n   },\n   \"then\": [\n   ]\n}\n</code></pre>","tags":["DATASTAGE","TESTING"]},{"location":"patterns/testing-datastage-flow-rejects/#result","title":"Result","text":"","tags":["DATASTAGE","TESTING"]},{"location":"patterns/testing-datastage-flow-rejects/#output-stage-with-rejects","title":"Output stage with rejects","text":"<p>The output stage can be Unit Tested by including:</p> <ul> <li>the write link in the then clause of the Unit Test Spec; and</li> <li>the reject in the given clause of the Unit Test Spec.</li> </ul> <p>The CSV data specified for the rejects link should contain records that will actually test the flow of records through the reject path(s) of the job.</p>","tags":["DATASTAGE","TESTING"]},{"location":"patterns/testing-datastage-flow-rejects/#flow-design_1","title":"Flow design","text":"","tags":["DATASTAGE","TESTING"]},{"location":"patterns/testing-datastage-flow-rejects/#test-specification_1","title":"Test specification","text":"<pre><code>{\n   \"given\": [\n      {\n         \"stage\": \"Output\",\n         \"link\": \"Rejects\",\n         \"path\": \"Output-Rejects.csv\"\n      }\n   ],\n   \"when\": {\n      \"parameters\": { }\n   },\n   \"then\": [\n      {\n         \"stage\": \"Output\",\n         \"link\": \"Write\",\n         \"path\": \"Output-Write.csv\"\n      }\n   ]\n}\n</code></pre>","tags":["DATASTAGE","TESTING"]},{"location":"patterns/testing-datastage-flow-rejects/#result_1","title":"Result","text":"","tags":["DATASTAGE","TESTING"]},{"location":"patterns/testing-datastage-stored-procedures/","title":"Test cases with stored procedure stages","text":"<p>A connector stage which supports stored procedures will not only connect to an external Database for processing but it will also produce output records which are not deterministic.  A DataStage test case specification needs to treat stored procedure-capable stages which will be stubbed during unit test execution.  This is done by adding the relevant stage's input link to the <code>then</code> clause of the test specification and the output link to the <code>given</code> clause.</p> <p>The CSV input specified by the given clause contains the data that will become the flow of records from the Stored Procedure stage. The data could simulate what would be produced by the real stored procedure if it had processed the Unit Test input records, however they don\u2019t have to.</p> <p>[!NOTE] This process is handled automatically by the DataStage test case creation process. This page acts as a reference to explain the structure of the JSON test specification generated for flows including following this pattern.</p>","tags":["DATASTAGE","TESTING"]},{"location":"patterns/testing-datastage-stored-procedures/#flow-design","title":"Flow design","text":"","tags":["DATASTAGE","TESTING"]},{"location":"patterns/testing-datastage-stored-procedures/#test-specification","title":"Test specification","text":"<pre><code>{\n    \"given\": [\n        {\n            \"path\": \"StoredProcedure-Output.csv\",\n            \"stage\": \"StoredProcedure\",\n            \"link\": \"Output\" \n        }\n    ],\n    \"then\": [\n        {\n            \"path\": \"StoredProcedure-Input.csv\",\n            \"stage\": \"StoredProcedure\",\n            \"link\": \"Input\"\n        }\n    ],\n    \"when\": {\n        \"parameters\": { }\n    }\n}\n</code></pre>","tags":["DATASTAGE","TESTING"]},{"location":"patterns/testing-datastage-stored-procedures/#result","title":"Result","text":"","tags":["DATASTAGE","TESTING"]},{"location":"patterns/testing-datastage-surrogate-key-generators/","title":"Testing flows with surrogate key generator stages","text":"<p>Surrogate Key Generators are backed by a Database or a Flat File and will produce output records which are not deterministic.  The use of a Database-backed Surrogate Key Generator will also require a live connection to an external Database which is not ideal for unit testing.  To unit test flow designs containing this type of surrogate key generator, the surrogate key generator stage needs to be removed from the flow and replaced with test case data.  This is done by adding the input link in the <code>then</code> clause of the test specification and the output link in the <code>given</code> clause.</p> <p>The CSV input specified by the given clause contains the data that will become the flow of records from the surrogate key generator stage.  The data could simulate what would be produced by the real surrogate key generator if it had processed the test case input records, however it doesn\u2019t have to.  The easiest way to simulate the surrogate key generator output records would be to copy the CSV specified in the <code>then</code> clause and add a new column to represent the generated key and set appropriate key values.</p>","tags":["DATASTAGE","TESTING"]},{"location":"patterns/testing-datastage-surrogate-key-generators/#flow-design","title":"Flow design","text":"","tags":["DATASTAGE","TESTING"]},{"location":"patterns/testing-datastage-surrogate-key-generators/#test-specification","title":"Test specification","text":"<pre><code>{\n   \"given\": [\n      {\n         \"stage\": \"KeyGenerator\",\n         \"link\": \"Output\",\n         \"path\": \"KeyGenerator-Output.csv\"\n      }\n   ],\n   \"when\": {\n      \"parameters\": {\n         \"MyKeyStartValue\": 100\n      }\n   },\n   \"then\": [\n      {\n         \"stage\": \"KeyGenerator\",\n         \"link\": \"Input\",\n         \"path\": \"KeyGenerator-Input.csv\"\n      }\n   ]\n}\n</code></pre>","tags":["DATASTAGE","TESTING"]},{"location":"patterns/testing-datastage-surrogate-key-generators/#result","title":"Result","text":"","tags":["DATASTAGE","TESTING"]},{"location":"patterns/testing-flows-using-datetime-references/","title":"Testing flows using date/time references","text":"<p>Repeatable DataStage tests require that the flow being tested produces deterministic data based on a set of predefined inputs and parameters.  Calculations based on the current date or time are common in DataStage flow designs but will cause the output produced by those flows to change depending on the date and time when its job is executed.  This page outlines practices aimed at ensuring jobs using current date calculations are able to be validly tested.</p>","tags":["DATASTAGE","TESTING"]},{"location":"patterns/testing-flows-using-datetime-references/#transformer-stages-using-system-time-and-date-functions","title":"Transformer Stages using system time and date functions","text":"<p>Transformer stages with derivations using the <code>CurrentDate()</code>, <code>CurrentTime()</code> or <code>CurrentTimestamp()</code> functions need to be considered carefully whn designing your tests. Unless your calculation requires a specific date and/or time then calls to the standard <code>CurrentDate()</code>, <code>CurrentTime()</code> and <code>CurrentTimestamp()</code> functions could potentially be substituted with calls to the <code>DSJobStartDate</code>, <code>DSJobStartTime</code> and <code>DSJobStartTimestamp</code> macros. This enables you to substitute them with a specific value during testing.  Add <code>DSJobStartDate</code>, <code>DSJobStartTime</code>, and <code>DSJobStartTimestamp</code> (as required) to the <code>parameters</code> clause of the test Specification's <code>when</code> node and set the appropriate date and time values used during Unit Testing.</p> <p>For example, imagine two Transformer stage variables using the following expressions:</p> <pre><code>BeforeToday =\nIf inPurchases.Purchase_Date &lt; DSJobStartDate Then \"Yes\" else \"No\"\n\nEarlierToday = \nIf inPurchases.Purchase_Date = DSJobStartDate and \n   inPurchases.Purchase_Time &lt; DSJobStartTime Then \"Yes\" else \"No\"\n</code></pre> <p>The <code>when</code> section of your test specification would look like this:</p> <pre><code>{\n    \"given\": [\n        ...\n    ],\n    \"when\": {\n        \"data_intg_flow_ref\": \"blah-blah-blah\",  \n        \"parameters\": {\n            \"DSJobStartDate\": \"2012-01-15\",\n            \"DSJobStartTime\": \"11:05:01\"\n        }\n    },\n    \"then\": [\n        ...\n    ]\n}\n</code></pre> Be careful when using multiple date/time macros <p>Exercise caution when setting <code>DSJobStartTimestamp</code> in conjunction with either <code>DSJobStartDate</code> or <code>DSJobStartTime</code> as the DataStage test case capability does not attempt to enforce logical consistency between these parameters. i.e. You could specify conflicting values for these macros which would create a contradictory logical condition. e.g. <pre><code>{\n    \"when\": {\n        \"data_intg_flow_ref\": \"blah-blah-blah\",  \n        \"parameters\": {\n            \"DSJobStartTimestamp\": \"2025-02-03 00:00:00\", \n            \"DSJobStartDate\": \"2024-04-05\"\n            \"DSJobStartTime\": \"09:30:00\"\n        }\n    }\n}\n</code></pre></p>","tags":["DATASTAGE","TESTING"]},{"location":"pipelines/","title":"Introduction","text":"<p>The latest version can always be found here: https://pages.github.ibm.com/datamigrators/devops-for-datastage/</p> <p>Download the latest (PDF) Download the latest (DOCX)</p> <ul> <li> <p> Set up in 5 minutes</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p> </li> <li> <p> Open Source, MIT</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p> </li> </ul>"},{"location":"testing/baselining-test-results/","title":"Recapture a test result baseline","text":"<p>As the logic of your flow changes, so the test data files representing your desired output will also need to change.  DataStage\u00ae can automatically re-baseline your expected output based on an execution of your DataStage job.  Note that while this process is similar to the process described in Capturing test data this process differs in that it only captures the output(s) of your job.</p> <p></p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/baselining-test-results/#process","title":"Process","text":"<ol> <li>In the test case editor, open the Test data in use tree and select the test output file(s) you want to re-baseline.</li> <li>In the data area above the table click the trash icon to delete the data file.</li> <li>Your test specification now refers to at least one CSV data file which no longer exists. Execute your test case without changing the specification. DataStage will identify that no expected results exist for the file(s) you\u2019ve deleted and re-create them using the data captured at runtime.  Note that test case will fail when executed in this mode.</li> <li>Re-execute the same test case job.  DataStage will now use the new baseline results files and your test case will pass.</li> </ol>","tags":["DATASTAGE","TESTING"]},{"location":"testing/capturing-test-data/","title":"Capturing test data","text":"<p>Each DataStage\u00ae development team will already have a set of test data that they use to verify their flow's correct operation.  DataStage\u00ae enables you to capture that data (regardless of whatever technology is currently used to supply it) and encapsulate it into a commonly managed, well governed artefact which can travel with your flow to repeatedly assert its consistent behavior in any downstream environment.  This existing test data can be captured by DataStage by running a flow in 'Data Capture' mode.</p> <p></p> <p>This process involves running your flow in a 'Capture' mode.  In this mode DataStage will interrogate the data flowing along the input and output links referenced in your test case specification and record the data it observes into the test data file defined (by your specification) for each link.  This permits the capture of structured and unstructured data from both batch and streaming data sources.</p> <p>The data flowing along a flow's output links is captured as the current definition of 'expected' output into the relevant output data files.  When you alter the flow's functionality you may well need to re-capture a new baseline of expected results.</p>","tags":["DATASTAGE","TESTING","CAPTURE"]},{"location":"testing/capturing-test-data/#process","title":"Process","text":"<ol> <li>In the test case editor click Capture data. You'll need to accept any 'Overwrite all test data' warnings you receive by clicking the Capture data button.</li> <li>You'll receive a message telling you the flow is running.  Select the Test history tab to browse the most recent history of test case job invocations, including jobs currently in progress.</li> <li>Once the job is complete select the Data tab and browse the newly-populated test data under the the Test data in use tree.</li> </ol>","tags":["DATASTAGE","TESTING","CAPTURE"]},{"location":"testing/configuring-test-data-storage/","title":"Configuring test data storage","text":"","tags":["DATASTAGE","TESTING"]},{"location":"testing/configuring-test-data-storage/#create-a-connection","title":"Create a connection","text":"<p>Start by creating a connection to a storage volume where test assets will be stored.</p> <ol> <li>From the CPD Cluster home page open an existing project or create a new project then, on the Assets tab, click New Asset &gt; Connect to a data source.</li> <li>On the resulting page select Storage volume and Next.</li> <li>On the Create connection: Storage volume page give your new connection a name and optional description.</li> <li>Select an available storage volume. If you don't already have an storage volume available \u2026</li> <li>click New volume.</li> <li>Select a namespace (the default will be fine).</li> <li>Give your storage volume a name and optional description.</li> <li>Select your preferred storage type and click Add.</li> <li>Under Personal credentials &gt; Input method select Enter credentials manually.</li> <li>Check the Use my platform login credentials then click Test connection.</li> <li>Assuming you have a successful connection, click Save.</li> </ol> <p>For more details see Adding connections to data sources in a project.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/configuring-test-data-storage/#add-the-connection-to-your-project-settings","title":"Add the connection to your project settings","text":"<p>Now you'll configure DataStage\u00ae to use your storage volume for storing test case assets.</p> <ol> <li>From the CPD Cluster home page select the Manage tab then, under Tools, select DataStage and then select the tab Test cases.</li> <li>For Test data connection type select Storage Volume.</li> <li>For Test data storage select the name of the Storage volume you created in the step above.</li> <li>For Default DataStage Test case job suffix specify a suffix which will be appended to all test case jobs to help distinguish them in the job log from invocations of their associated flows. e.g. <code>Test Case Job</code>. Note that a leading space has been included here as DataStage will not automatically add one for you.</li> </ol>","tags":["DATASTAGE","TESTING"]},{"location":"testing/creating-datastage-test-cases/","title":"Creating a DataStage test case","text":"<p>Unit tests can be created for DataStage\u00ae flows using the DataStage user interface.  When DataStage creates a test case it performs the following steps:</p> <ol> <li>Inspect your flow design to identify all source and target stages.</li> <li>Read the metadata definition of each source stage input link and target stage output link (i.e. all data flowing into and out of your flow).  Note that each source stage may be configured with multiple output links, and each target stage may be configured with multiple input links.</li> <li>Create an empty test case data file for each source and target link, with appropriate metadata definitions.</li> <li>Interrogate your flow's parameters.</li> <li>Create a test case specification which provides references to all of your flow's parameters as well as each newly-created test data file.</li> </ol> <p></p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/creating-datastage-test-cases/#process","title":"Process","text":"<p>You can create DataStage test cases either as a new asset or directly from within the DataStage designer canvas.</p> <p>From the CPD Cluster home page open an existing project or create a new project then, on the Assets tab, click New Asset &gt; Create reusable DataStage components &gt; Test case.</p> <p>To edit a test case from the DataStage canvas, go to an existing or new flow and click the Test cases icon to open up the test cases panel. Click New test case.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/creating-datastage-test-cases/#defining-test-case-properties","title":"Defining test case properties","text":"<ol> <li>On the Create test case page specify the name and optional description for the DataStage test case.  If you invoked this action when creating a new asset you'll also need to specify a DataStage flow with which to associate this test case.</li> <li>Click Next.</li> <li>On the Select stubbed links page select the flow links which will be stubbed in the test. This determines the \u2026<ul> <li>input links into which test data will be injected, and</li> <li>output links from which data will be compared to the expected output.</li> </ul> </li> <li>Click Next</li> <li>Specify the names of parameters or parameter sets for which your test will supply hard-coded values.</li> <li>Click Create.</li> </ol>","tags":["DATASTAGE","TESTING"]},{"location":"testing/creating-datastage-test-cases/#creating-test-data","title":"Creating test data","text":"<p>There are a number of ways you can derive data for your test case.  Start by opening you test case and from the Data tab selecting the test data file you wish to edit.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/creating-datastage-test-cases/#capture-test-data","title":"Capture test data","text":"<p>Use this method to capture data at runtime from a job invocation.  For more details see Capturing test data.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/creating-datastage-test-cases/#import-test-data","title":"Import test data","text":"<p>You can import locally-stored CSV data into your IBM Cloud Pak DataStage test data files:</p> <ol> <li>Click the Import button above the test data table.</li> <li>Upload your file by dragging and dropping your file, or clicking the link to specify a file.</li> <li>Click Import.</li> </ol> <p>Note that any existing test data in your selected file will be overwritten.</p> <p>You can read more about supplying the data and parameters that define your tests in editing DataStage test cases.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/editing-datastage-tests/","title":"Editing a DataStage test case","text":"<p>You can enter the DataStage\u00ae test cases editor either by selecting the Test case asset on the project page or from within the DataStage designer canvas.</p> <ul> <li>Open an existing project then open the Assets tab and under the Asset types panel select DataStage components &gt; Test cases from where you can click the name of the test case you wish to edit.</li> <li>From the DataStage canvas open an existing DataStage flow then click the Test cases icon to open up the test cases side panel from where you can click the name of the test case you wish to edit.</li> </ul> <p>This will bring you to the test case editor which allows you to inspect and modify your test case specification as well as edit the contents of your input and output test data files.</p> <p></p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/editing-datastage-tests/#editing-the-test-case-specification","title":"Editing the test case specification","text":"<p>Selecting Specification from the Data tab will display the test case's specification.</p> <p>For a detailed explanation of the format of this JSON specification and the options available for controlling how your test case behaves see Test specification format.</p> <p>Each test data file referenced in your JSON specification (whether it represents input data or expected output data) will appear as a file under the Test data in use tree.  Selecting one of these will enable you to view and edit the test data.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/editing-datastage-tests/#editing-test-data","title":"Editing test data","text":"<p>As well as using capture and import methods to derive test data, you can also manually enter test data into your test data files.  The test data table can be edited interactively like a spreadsheet and provides the following notable capabilities:</p> <ul> <li>Undo/redo of editing actions is supported with the traditional keyboard shortcuts Control-Z and Shift-Control-Z (Windows) or Command-Z and Shift-Command-Z (macOS).</li> <li>Values entered into a cell are validated based on the column's metadata definition. Invalid data is highlighted in red.</li> </ul>","tags":["DATASTAGE","TESTING"]},{"location":"testing/editing-datastage-tests/#modifying-metadata","title":"Modifying metadata","text":"<ul> <li>Rows can be added by selecting the Add row icon above the test data table.</li> <li>Rows can be deleted by selecting the three dots on the row header and clicking Delete.</li> <li>Columns can be added by selecting the Add column icon above the test data table.</li> <li>Columns can be deleted by selecting the three dots on the column header and clicking Delete column.</li> </ul> <p>Modify the metadata of a test data column by selecting the three dots on the column header and clicking Edit column.  The resulting panel enables you to specify the column's name, data type, nullability, length, and extended metadata. Click Save to record your changes.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/editing-datastage-tests/#modifying-test-data-outside-the-datastage-interface","title":"Modifying test data outside the DataStage interface","text":"<p>You can export IBM Cloud Pak DataStage test data files to locally-stored CSV files for offline editing:</p> <ol> <li>Click the menu overflow (V) button above the test data table to reveal more options and click Download .</li> <li>Modify the local filename as required and click Download.  The resulting CSV file will be downloaded to your browser's default download location.</li> </ol> <p>Once edited you can re-import your updated by clicking the Import button above the test data table and specifying your edited file before clicking Import.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/editing-datastage-tests/#managing-test-cases","title":"Managing test cases","text":"","tags":["DATASTAGE","TESTING"]},{"location":"testing/editing-datastage-tests/#rename-a-test-case","title":"Rename a test case","text":"<p>You can rename a test case from the asset browser by moving your pointer over the test case name and clicking the edit icon which appears alongside it. Editing the name in the table cell and press the Return key or click the green checkmark to save your changes.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/editing-datastage-tests/#delete-a-test-case","title":"Delete a test case","text":"<p>You can delete a test case from the asset browser by clicking the 'three dots' icon of the test case name and selecting Delete.  On the resulting dialog verify the relationships of the asset you're deleting and click Delete to confirm.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/editing-datastage-tests/#save-changes","title":"Save changes","text":"<p>Once you're happy with your test data changes you can store your changes by clocking the Save button on the test data editor toolbar.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/editing-datastage-tests/#export-a-test-case","title":"Export a test case","text":"<p>Export a test case to a zip file by clicking the Export icon on the test case toolbar.  On the resulting dialog confirm the name of the export file and click Download.  Note that this export does not contain test data.  To export test data for external modification see Modifying test data outside the DataStage interface above.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/editing-datastage-tests/#test-case-settings","title":"Test case settings","text":"<p>Click the Settings icon to open the test case settings panel which enables you to specify options for the selected test.</p> <p>History record storage allows you to specify the number of historical test results you wish to retain. This can be specified either by the number of days or the number of runs.</p> <p>Schedule allows you to specify a time and date when you want your test case job to be automatically executed and (optionally) the frequency with which the job should be re-executed.</p> <p>Click Save to store your selections.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/excluding-columns-from-tests/","title":"Excluding columns from tests","text":"<p>You can omit selected columns from the test case output comparison by adding the columns to be ignored to an <code>ignore</code> array in the relevant specification's <code>then</code> property.</p> <pre><code>{\n    \"then\": [\n        {\n            \"path\": \"ODBC_orders.csv\",\n            \"stage\": \"ODBC_order\",\n            \"link\": \"order_out\",\n            \"ignore\": [\n                \"Creation_date\",\n                \"Last_updated\"\n            ]\n        }\n    ]\n}\n</code></pre> <p>Note: Ignoring columns will prevent columns containing non-deterministic from affecting test results but will also omit those columns from test comparisons, so unexpected output in those columns, or changes in the output of those columns, will not be detected by your test case.  This reduces your test coverage and should be avoided if possible. A common technique to avoid non-deterministic outputs is to ensure all inputs data sources and flow parameters are stubbed by your test specification.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/executing-datastage-test-cases/","title":"Executing a DataStage test case","text":"<p>You can execute DataStage\u00ae test cases either from the CPD Cluster home page, the DataStage designer canvas, or the DataStage test case editor.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/executing-datastage-test-cases/#from-the-cpd-cluster-home-page","title":"From the CPD Cluster home page","text":"<ol> <li>Open an existing project and select the Jobs tab.</li> <li>Click the name of the test case you wish to invoke.  This will display the job details panel.</li> <li>Click the Run job button in the job details toolbar to invoke the test.</li> <li>When the status icon shows your test has completed click the timestamp to see test results.</li> </ol>","tags":["DATASTAGE","TESTING"]},{"location":"testing/executing-datastage-test-cases/#from-the-datastage-canvas","title":"From the DataStage canvas","text":"<ol> <li>Open an existing DataStage flow for which you have created a test case.</li> <li>Click the Test cases icon to  open up the test cases side panel.</li> <li>Click the Run icon alongside the name of the test case you wish to invoke.</li> <li>When the status icon shows your test has completed click the timestamp to see test results.</li> </ol>","tags":["DATASTAGE","TESTING"]},{"location":"testing/executing-datastage-test-cases/#from-the-datastage-test-case-editor","title":"From the DataStage test case editor","text":"<ol> <li>Open an existing test case.</li> <li>Click the Run button on the toolbar to invoke your test.</li> <li>Click View result on the notification that appears when your job is complete.</li> </ol> <p>Once your test is complete you should verify your test results.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/executing-datastage-test-cases/#background","title":"Background","text":"<p>When DataStage executes your test case it will dynamically replace your flow's input stages at runtime with components which inject data from the relevant CSV data files into your job on the links specified in your test specification.  Any source data repositories (files, databases, etc.) included in your test specification will not be connected to or read during a test case execution.</p> <p>Similarly, your flow's output stage(s) will be replaced at runtime with components which read the incoming data and compare it to the relevant CSV data files containing the output expected on those links.  Any differences are reported in the test results.</p> <p></p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/high-volume-tests/","title":"High Volume DataStage Tests","text":"<p>During the execution of a DataStage\u00ae test case the data produced by a job (on one or more output links) is compared against expected test data to identify and report on any differences.  When testing with large volumes of data, the comparison process may consume too much memory and cause your test job to abort with a fatal error.  The simplest approach to resolving this issue is to reduce your test data volume to the smallest number of records necessary to exercise each code path through your flow.  Doing so will ensure that your test cases execute quickly and can be easily understood and maintained.</p> <p>In the event that test data available to you cannot easily be reduced, the memory required by the data comparison process can be reduced by specifying a Cluster Key in the test specification.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/high-volume-tests/#using-cluster-keys-in-datastage-tests","title":"Using Cluster Keys in DataStage Tests","text":"<p>Defining a Cluster Key will cause DataStage to split the actual data output and expected data into multiple, smaller subsets before the data is compared.  Data is split such that each subset will only contain records that have the same values for all columns that make up the Cluster Key - a process somewhat analogous to DataStage partitioning.  The data are then sorted and a comparison of actual and expected data is performed using multiple, smaller operations which require less memory and are performed sequentially.  </p> <p>Test result behavior: Due to the iterative nature of comparisons using a Cluster Key, each record which has differences in the Cluster Key columns will be reported as 1 added record and 1 removed record rather than shown as a single record with a change indicator.</p> <p>A good Cluster Key is one that results in data subsets which strike a balance between the following factors:</p> <ul> <li>Each subset should fit in memory during comparison. Test execution will abort when memory thresholds are breached.</li> <li>Are as large as possible given the memory constraint. Lots of tiny subsets will degrade comparison performance.</li> </ul> <p>Selecting an appropriate Cluster Key might require several iterations to find a column (or combination of columns) which not only prevents Job aborts but also keeps run times acceptable.  Unless you are comparing unusually wide records, a good starting point is to aim for each subset of data to contain no more than 1,000 records and adjust the Cluster Key if memory thresholds continue to be breached.</p> <p>If you have used Interception to capture some input and / or expected test data for a DataStage Test and subsequently decide you want to apply a Cluster Key, you don\u2019t have to re-run Interception. This is also the case if you\u2019ve manually created any test data files. The Cluster Key is used at run time and therefore doesn\u2019t require any additional data preparation by the user.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/high-volume-tests/#example","title":"Example","text":"<p>Consider the situation where a DataStage Test has to compare several million financial transaction records with the following schema on the 'order_out' link of stage 'ODBC_order':</p> Column name SQL type Length Scale Nullable Transaction_Date Timestamp No Account_Id VarChar 20 No Type_Code VarChar 5 No Description VarChar Yes Amount Decimal 18 2 No <p>The test specification can be updated with a Cluster Key to enable iterative comparison of actual and expected test data.  In this example, <code>Account_Id</code> and <code>Type_Code</code> are defined as the compound Cluster Key:</p> <pre><code>{\n    \"then\": [\n        {\n            \"path\": \"ODBC_orders.csv\",\n            \"stage\": \"ODBC_order\",\n            \"link\": \"order_out\",\n            \"cluster\": [\n                \"Account_Id\",\n                \"Type_Code\"\n            ]\n        }\n    ],\n}\n</code></pre> <p>Note: Cluster Keys are specified on a per-link basis. DataStage flows with multiple output links can use any combination of clustered and non-clustered comparisons within a single test specification.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/high-volume-tests/#caveats","title":"Caveats","text":"<p>Cluster keys should be chosen to break Actual and Expected data into clusters which are small enough to fit in memory.</p> <p>Note that if a Unit Test detects a value difference in a column which is a cluster key column, then the Unit Test difference report (which would normally describe the difference as a \u2018modified\u2019 row when not using a cluster key) will now describe the difference as distinct \u2018added\u2019 and \u2018removed\u2019 entries.  </p> <p>As useful as Cluster Keys are, it\u2019s poor practice to simply apply them to every DataStage test that has to process high data volumes. You will almost certainly find combinations of flows and data volumes in your project where no Cluster Key will reduce the memory demands of a DataStage test enough to avoid Job aborts (See Unit Test throws OutOfMemoryError exception). In these situations you can manage your test data volumes by \u2026</p> <ul> <li>carefully selecting a subset of records from your data sources,</li> <li>using the DataStage's data fabrication features, or</li> <li>both of these approaches in combination.</li> </ul>","tags":["DATASTAGE","TESTING"]},{"location":"testing/migrating-datastage-tests-from-older-versions/","title":"Migrating test cases from older versions of DataStage","text":"<p>Users of IBM\u00ae DataStage\u00ae v11.x who built DataStage unit tests using MettleCI will be familiar with the YAML syntax used to specify those unit tests. Test cases for Cloud Pak DataStage are different in that they are specified using JSON rather than YAML.  Despite this syntactic difference, the options and structure of a test specification remain identical.</p> <p>Existing MettleCI unit tests are easily migrated into DataStage on Cloud Pak for Data using the <code>mettleci unittest migrate</code> command available in the MettleCI command line.  The documentation for this command describes the process you need to undertake to safely migrate your tests to Cloud Pak.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/row-count-comparisons/","title":"Row count comparisons","text":"<p>You can configure a DataStage\u00ae test case to only compare outputs' row counts, rather than the content of those rows, by setting the <code>checkRowCountOnly</code> property to true.</p> <pre><code>{\n    \"then\": [\n        {\n            \"path\": \"ODBC_orders.csv\",\n            \"stage\": \"ODBC_order\",\n            \"link\": \"order_out\",\n            \"checkRowCountOnly\": true\n        }\n    ],\n}\n</code></pre> <p>Note that the <code>checkRowCountOnly</code> property takes a boolean value which does not use quotes.</p> <p>The test case report containing a single cell comparing the expected and actual output row count (of the form <code>Expected-&gt;Actual</code>.)</p> <p></p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/selective-stubbing/","title":"Selective stubbing","text":"<p>The process of 'stubbing' involves using a fabricated version of an external data source (a 'stub') that returns specific, deterministic values or behaviors. Stubs can be used to test code that relies on external data sources that are not available at a given time or in a given environment, or which are non-deterministic.</p> <p>When you specify a DataStage\u00ae unit test you are defining stub data and telling DataStage which link(s) to stub with that data. There may be some instances where you wish to define a test case that only injects test data into some of your flow's input links, and allow other source stages to operate normally during a test execution. These input links which are not stubbed are not referenced in your test specification and will connect to their configured data source and retrieve data at runtime.</p> <p>To define a link which should not be stubbed simply omit the link from the <code>given</code> section of your test specification.</p> <p>For example \u2026</p> <pre><code>{\n    \"given\": [\n        {\n            \"path\": \"filePurchasesIn.csv\",\n            \"stage\": \"dsEX_Purchase\",\n            \"link\": \"inPurchase\" \n        }\n    ],\n    \"then\": [\n        {\n            \"path\": \"filePurchasesOut.csv\",\n            \"stage\": \"dsTR_Purchase\",\n            \"link\": \"outPurchase\"\n        }\n    ],\n    \"when\": {\n        \"data_intg_flow_ref\": \"blah-blah-blah\",  \n        \"parameters\": {\n        }\n    }\n}\n</code></pre> <p> </p> <p>Note: When defining test cases that use selective stubbing you should to exercise caution when deploying those test cases to downstream test environments.  Those environments will need to be configured to permit stages which have not been stubbed to retrieve data from their configured data sources.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/test-datastage-sparse-lookup-stages/","title":"Test Cases with sparse lookups","text":"<p>Note: This page is specific to sparse lookups.  Lookup stages configured to use normal lookups do not need any special considerations for DataStage unit testing.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/test-datastage-sparse-lookup-stages/#using-a-sparse-lookup-explicit-test-method","title":"Using a sparse Lookup ('Explicit' test method)","text":"<p>When designing DataStage flows using a lookup stage you configure the lookup to operate in normale or sparse mode by changing the lookup Lookup type in the Output tab of the database stage providing  the lookup reference.  When a DataStage flow featuring a sparse lookup is compiled executed, however, the  lookup stage is not used to perform the sparse lookup.  Instead, DataStage replaces the lookup stage with  the database operator which is responsible for reading input rows, looking up values from the database,  and producing output records.  It is for this reason that all database log messages in the DataStage Director  are attributed to the Lookup stage and why the Database stage never appears in the Monitor of the DataStage Director.</p> <p>Open image-20200129-024550.png</p> <p>To Unit Test job designs using Sparse Lookup stages the sparse lookup functionality needs to be explicitly  replaced with user-supplied Unit Test data:</p> <p>Open image-20221116-231138.png</p> <p>The most explicit way to configure Unit Testing to replace a Sparse Lookup with Test data is by adding the input  link to the then (expected outputs) clause of the Unit Test Spec and the output link to the given (supplied inputs)  clause of the Job\u2019s Unit Test Specification.  </p> <p>The CSV file specified in the then clause contains the data that will be be compared to the data flow of records arriving  at the input of the Sparse Lookup stage.  The data should describe what records are expected to be used to provide the  sparse  lookup\u2019s key columns.</p> <p>The CSV file specified in the given clause contains the data that will be become the data flow of records from the output  of the Sparse Lookup stage.  The data should simulate what would be produced by the real Sparse Lookup Stage if it had  actually processed the Unit Test input records against the real database reference source, however they don't have to.</p> <p>Open image-20200129-014439.png</p> <pre><code>given:\n  - stage: SparseLookup\n    link: Output\n    path: SparseLookup-Output.csv\nwhen:\n...\nthen:\n  - stage: SparseLookup\n    link: Input\n    path: SparseLookup-Input.csv\n</code></pre> <p>Open image-20200129-014525.png</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/test-datastage-sparse-lookup-stages/#sparse-lookup-stage-replace-method","title":"Sparse Lookup Stage ('Replace' method)","text":"<p>MettleCI Unit Test Harness version 1.1-379 and later provides a convenient alternative capability which uses the new Unit Test Specification spareseLookup and associated key clauses to replace the entire Sparse Lookup stage with Test Data while only requiring the user to supply Test Data for the reference link:</p> <p>Open image-20200129-014439.png</p> <p><pre><code>given:\n  - sparseLookup: SparseLookup\n    path: Database-Reference.csv\n    key:\n      - KEY_COLUMN_1\n      - KEY_COLUMN_2\n...\n\nOpen image-20221116-232511.png\n\n \n\nIn this mode the Sparse Lookup stage is replaced entirely with a Unit Test version of the sparse lookup which uses the specified Test Data as the lookup data.  It is provided as a convenient alternative to explicitly replacing Sparse Lookup stage input and output links, allowing the remaining logic in the job to be tested while not actually testing the behaviour of DataStage\u2019s Sparse Lookup stage.  \n\nWhen generating Unit Tests from Job designs containing Sparse Lookups, MettleCI Workbench version 1.0-1483 and later will automatically apply this Unit Test pattern and generate test specifications which replace Sparse Lookup stages entirely.\n\n## Known Limitations\n\nReplacing the Sparse Lookup stage with a Unit Test version of the sparse lookup comes with some limitations that DataStage developers should keep in mind.  \n\nUnit Test Sparse Lookup stages simulate typical key matching and assumes data equality with three-valued-logic semantics.  Custom key-matching logic embedded in custom lookup SQL (eg. SQL with a where clause like where KEY_COLUMN=Upper(ORCHESTRATE.KEY_COLUMN)) will not be replicated.\n\nWhen running Unit Testing in Interception mode, one additional Sort operation per Unit Test Sparse Lookup stage is required.  For sparse lookup stages which produce large volumes of output data this can have an adverse affect on job execution times when running in Interception mode.\n\nReference data records that contain Nulls or Default Values for all columns are ignored during interception when the Sparse Lookup stage is set to Continue on Lookup Failure.  This will have no functional impact on the output of the Sparse Lookup Stage and is expected behaviour.\n\nWhere you consider these limitations unacceptable you can revert to the original (explicit) method for replacing Sparse Lookups.\n\nA pragmatic approach for Multiple Sparse Lookups\nFor jobs where the vast majority of job logic is implemented using Sparse Lookup stages, replacing all lookups with Unit Test data would result in little-to-no DataStage logic being tested (as illustrated below).  \n\nOpen image-20200129-035608.png\n\nFor the type of Job design show above, a traditional explicit testing approach would necessitate the developer providing 8 sets of test data! An alternative testing approach is to leave the Sparse Lookups in place and replace only the input and output stages with Unit Test data.  A live Database connection will be required during testing but the when clause can be used to set job parameters that dictate database connection settings. \n\nTechnically this is an Integration Test, not a Unit Test: The Unit Test Harness does not provide any functionality for populating database reference tables with Unit Test data prior to test execution, users are responsible for managing Integration Test setup and tear down through governance and/or CI/CD pipeline customisation.\n\nOpen image-20200129-040758.png\n\n \n</code></pre> given:   - stage: Source     link: Input     path: Source-Output.csv when:   parameters:     DbName: MyUnitTestDb     DbUser: MyUnitTestUser     DbPass: {iisenc}dKANDae233DJIQeiidm== then:   - stage: Target     link: Output     path: Target-Output.csv ```</p> <p>Open image-20200129-040641.png</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/test-specification-format/","title":"DataStage test specification format","text":"<ul> <li>Structure overview</li> <li>Given these inputs</li> <li>Sparse Lookup sources</li> <li>When these conditions are met</li> <li>Then expect these outputs</li> </ul>","tags":["DATASTAGE","TESTING"]},{"location":"testing/test-specification-format/#structure","title":"Structure","text":"<p>A DataStage\u00ae test case specification (often abbreviated \u2018Spec') is a JSON-formatted file which uses a grammar modelled loosely on the Gherkin syntax used by the Cucumber testing tool. The overall structure follows the common Gherkin pattern \u2026</p> <pre><code>{\n    \"given\": [\n        { This test data on input link 1 },\n        { This test data on input link 2 }\n    ],\n    \"when\": {\n        I execute the test case with these options and parameter values\n    },\n    \"then\": [\n        { Expect this data to appear on output link 1 },\n        { Expect this data to appear on output link 2 }\n    ]\n}\n</code></pre> <p>Note: The user interface may order the JSON objects alphabetically (<code>given</code> &gt; <code>then</code> &gt; <code>when</code>) but this has no effect on the functionality of the test.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/test-specification-format/#given","title":"Given","text":"<p>The <code>given</code> property array associates test data files with your flow's input , thereby defining the test values you wish to inject into your flow's inputs at runtime.</p> <p>For example:</p> <pre><code>{\n    \"given\": [\n        {\n            \"path\": \"fileCustomers.csv\",\n            \"stage\": \"sfCustomers\",\n            \"link\": \"Customers\" \n        },\n        {\n            \"path\": \"fileOrders.csv\",\n            \"stage\": \"sfOrders\",\n            \"link\": \"Orders\"\n        }\n    ],\n}\n</code></pre> <p>Some source stages can be configured with multiple output links so each input in your test specification's <code>given</code> property array is uniquely identified using a combination of the stage and link names to eliminate ambiguity.  The array also contains a <code>path</code> property to identify the test data CSV file containing the test data that is to be injected on each incoming link.</p> <p>Note that not every stage in a job must be provided with test data.  You can easily craft a test specification which uses test data for only a subset of flow stages.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/test-specification-format/#sparse-lookup-sources","title":"Sparse Lookup sources","text":"<p>When an input source is used with a Sparse Lookup stage then rather than using the stage property to specify the input you will use the <code>sparseLookup</code> property.</p> <p>For example:</p> <pre><code>{\n    \"given\": [\n        {\n            \"path\": \"fileCustomers.csv\",\n            \"stage\": \"sfCustomers\",\n            \"link\": \"Customers\" \n        },\n        {\n            \"sparseLookup\": \"SparseLookup\",\n            \"path\": \"Database-Reference.csv\",\n            \"key\": [\n                \"KEY_COLUMN_1\",\n                \"KEY_COLUMN_2\"\n            ]\n        }\n    ],\n}\n</code></pre> <p>The <code>sparseLookup</code> property identifies a JSON object which specifies \u2026</p> <ul> <li>the value defining the name of the sparse lookup reference stage,</li> <li>a path to the relevant CSV test data file, and</li> <li>a list of key columns to be used for the sparse lookup.</li> </ul>","tags":["DATASTAGE","TESTING"]},{"location":"testing/test-specification-format/#when","title":"When","text":"<p>The <code>when</code> property array specifies which job will be executed during testing as well as any parameters (including job macros) that affect the data produced by the job.</p> <p>For example, this specification will</p> <p>Substitute hardcoded values for the <code>DSJobStartDate</code> and <code>DSJobStartTime</code> macros and the <code>paramStartKey</code> parameter:</p> <pre><code>{\n    \"when\": {\n        \"data_intg_flow_ref\": \"3023970f-ba2dfb02bd3a\",  \n        \"parameters\": {\n            \"DSJobStartDate\": \"2012-01-15\",\n            \"DSJobStartTime\": \"11:05:01\",\n            \"paramStartKey\": \"100\"\n        }\n    },\n}\n</code></pre> <p>One application of the <code>parameters</code> property is to supply values to make flows that rely on system date and time information produce a deterministic output by hard coding those values when testing.</p> <p>Note that the <code>data_intg_flow_ref</code> property is an internally-generated DataStage reference to the flow with which this test is associated and should not be changed.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/test-specification-format/#then","title":"Then","text":"<p>The <code>then</code> property array associates test data files with your flow's output links.</p> <pre><code>{\n    \"then\": [\n        {\n            \"path\": \"ODBC_customers.csv\",\n            \"stage\": \"ODBC_customer\",\n            \"link\": \"customer_out\"\n        },\n        {\n            \"path\": \"ODBC_orders.csv\",\n            \"stage\": \"ODBC_order\",\n            \"link\": \"order_out\"\n        }\n    ],\n}\n</code></pre> <p>Similar to the <code>given</code> property, because some target stages can be configured with multiple input links the test specification's <code>then</code> property array uniquely identifies links using a combination of the stage and link names. The array also contains a <code>path</code> property to identify the test data CSV file containing the expected test output that will be compared to the actual data appearing on each outgoing link.</p> <p>Other properties which extend the capabilities of your test case can be included in the <code>then</code> property array:</p> <ul> <li>The <code>ClusterKey</code> property: Improve performance of test cases when using data volumes</li> <li>The <code>checkRowCountOnly</code> property: Configure your tests to only count the number of rows</li> <li>The <code>ignore</code> property: Exclude specific columns from test comparisons</li> </ul>","tags":["DATASTAGE","TESTING"]},{"location":"testing/testing-datastage-flows/","title":"Getting Started With Testing DataStage Flows","text":"<p>DataStage\u00ae test cases are design-time assets that use data files to define the inputs and expected outputs of your DataStage flows.</p> <p>The basic building blocks of a test case are:</p> <ul> <li>A test specification</li> <li>One or more test data input files</li> <li>One or more test data output files</li> </ul> <p>Each DataStage test case is associated with a single DataStage flow. You can create DataStage test cases as a new asset or directly from within the DataStage designer canvas.  A DataStage test case is executed by a job in a manner similar to its associated DataStage flow. During execution the input data files are injected into your flow's incoming links and the data appearing on the output links are compared to the output files containing the expected outputs. Any differences in the two will cause the test to fail and the differences to be reported alongside the test case's job log.  </p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/testing-datastage-flows/#using-datastage-test-cases","title":"Using DataStage test cases","text":"<ol> <li>Configuring test data storage</li> <li>Creating DataStage test cases</li> <li>Editing DataStage tests</li> <li>Executing DataStage tests</li> <li>Verifying DataStage test results</li> <li>Migrating test cases from older versions of DataStage</li> </ol>","tags":["DATASTAGE","TESTING"]},{"location":"testing/troubleshoot-testing/","title":"Troubleshooting","text":"Problem Resolution I've modified my flow design and my test no longer passes Create a new test result baseline. The test case editor display the following message:<code>No connection has been defined on the project. Some features may be limited.</code> Configure a connection to store your test data.","tags":["DATASTAGE","TESTING"]},{"location":"testing/troubleshooting/","title":"Troubleshooting","text":"Problem Resolution I've modified my flow design and my test no longer passes Create a new test result baseline. The test case editor display the following message:<code>No connection has been defined on the project. Some features may be limited.</code> Configure a connection to store your test data.","tags":["DATASTAGE","TESTING"]},{"location":"testing/verifying-test-results/","title":"Verifying test results","text":"<p>You can verify DataStage\u00ae test results either from the CPD Cluster home page, the DataStage designer canvas, or the DataStage test case editor.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/verifying-test-results/#from-the-cpd-cluster-home-page","title":"From the CPD Cluster home page","text":"<ol> <li>Open an existing project and select the Jobs tab.</li> <li>Click the name of the test case you wish to inspect.  This will display the job details panel.</li> <li>Click the timestamp of a test to see its results.</li> </ol>","tags":["DATASTAGE","TESTING"]},{"location":"testing/verifying-test-results/#from-the-datastage-canvas","title":"From the DataStage canvas","text":"<ol> <li>Open an existing DataStage flow for which you have created a test case.</li> <li>Click the Test cases icon to open up the test cases side panel.</li> <li>Click the timestamp of a test to see its results.</li> </ol>","tags":["DATASTAGE","TESTING"]},{"location":"testing/verifying-test-results/#from-the-datastage-test-case-editor","title":"From the DataStage test case editor","text":"<ol> <li>Open an existing test case and select the Test history tab.</li> <li>Click the timestamp of a test to see its results.</li> </ol> <p>On the resulting Run details page select the Test results tab to see details about your test outcome.  Successful tests will present a simple acknowledgement message:</p> <p></p> <p>Test case errors will produce a difference report detailing how the expected and actual results differ from one another.</p> <p></p> <p>A difference report will be available for each failed test - i.e. each test where the expected and actual results varied.  For DataStage flows with multiple test failures (for multiple stubbed outputs) you can select which difference report to display by selecting the relevant output from the Stubbed link drop down box.</p>","tags":["DATASTAGE","TESTING"]},{"location":"testing/verifying-test-results/#the-difference-report","title":"The difference report","text":"<p>Every DataStage test case involved the comparison of at least one Actual result set, produced by your Flow, and an associated Expected result set, defined by your test case. The differences in these result sets is expressed in a tabular form which describe, using indicators in row headers, column headers, or cells, the operations that would be required to modify the Expected data to match the Actual data.</p> <p>Taking the example test report above:</p> Change type Indicator Example Inserted rows An additional, unexpected row (for customer 'Ardith Beahan') is present Deleted rows The expected row (for customer 'Doc Brown') is missing Inserted columns An additional, unexpected INTEGER column CENTS was produced Deleted columns The expected TINYINT column MEMBERSHIP was not found Modified column metadata Additional header row A VARCHAR column was renamed from <code>FIRST_NAME</code> to <code>FirstName</code> as indicated by an additional header row Modified cell values A modified value (of the form <code>Expected-&gt;Actual</code>) in the DOLLARS columns for person 'Josianne Mante'","tags":["DATASTAGE","TESTING"]},{"location":"tags/","title":"Tags","text":"<p>Following is a list of relevant tags:</p>"},{"location":"tags/#capture","title":"CAPTURE","text":"<ul> <li>Capturing test data</li> </ul>"},{"location":"tags/#datastage","title":"DATASTAGE","text":"<ul> <li>MettleCI Command Shell</li> <li>Test Cases with local and shared containers</li> <li>Testing flows with rejects</li> <li>Test cases with stored procedure stages</li> <li>Testing flows with surrogate key generator stages</li> <li>Testing flows using date/time references</li> <li>Recapture a test result baseline</li> <li>Capturing test data</li> <li>Configuring test data storage</li> <li>Creating a DataStage test case</li> <li>Editing a DataStage test case</li> <li>Excluding columns from tests</li> <li>Executing a DataStage test case</li> <li>High Volume DataStage Tests</li> <li>Migrating test cases from older versions of DataStage</li> <li>Row count comparisons</li> <li>Selective stubbing</li> <li>Test Cases with sparse lookups</li> <li>DataStage test specification format</li> <li>Getting Started With Testing DataStage Flows</li> <li>Troubleshooting</li> <li>Troubleshooting</li> <li>Verifying test results</li> </ul>"},{"location":"tags/#testing","title":"TESTING","text":"<ul> <li>MettleCI Command Shell</li> <li>Test Cases with local and shared containers</li> <li>Testing flows with rejects</li> <li>Test cases with stored procedure stages</li> <li>Testing flows with surrogate key generator stages</li> <li>Testing flows using date/time references</li> <li>Recapture a test result baseline</li> <li>Capturing test data</li> <li>Configuring test data storage</li> <li>Creating a DataStage test case</li> <li>Editing a DataStage test case</li> <li>Excluding columns from tests</li> <li>Executing a DataStage test case</li> <li>High Volume DataStage Tests</li> <li>Migrating test cases from older versions of DataStage</li> <li>Row count comparisons</li> <li>Selective stubbing</li> <li>Test Cases with sparse lookups</li> <li>DataStage test specification format</li> <li>Getting Started With Testing DataStage Flows</li> <li>Troubleshooting</li> <li>Troubleshooting</li> <li>Verifying test results</li> </ul>"}]}